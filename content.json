{"meta":{"title":"DreamLin's blog","subtitle":"","description":"","author":"DreamLin","url":"http://example.com","root":"/"},"pages":[{"title":"关于我","date":"2021-05-18T12:28:45.000Z","updated":"2024-04-05T07:19:53.027Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"家乡:福建泉州 爱好:音乐,运动,做饭"}],"posts":[{"title":"mysql之redo log原理","slug":"mysql之redo log原理","date":"2024-01-09T04:39:00.000Z","updated":"2024-04-09T00:42:09.302Z","comments":true,"path":"2024/01/09/mysql之redo log原理/","link":"","permalink":"http://example.com/2024/01/09/mysql%E4%B9%8Bredo%20log%E5%8E%9F%E7%90%86/","excerpt":"","text":"redo logredo log记录对页的修改操作,其具体指的是redo log缓冲区和redo log文件,redo log缓冲区是内存中的概念,而redo log文件是磁盘中的概念.redo log可以保证事务的原子性和持久性. 原理当执行一个事务时,事务中有对数据的修改操作,那么会将具体的修改记录成日志,本质上是记录对页的某个偏移位置的修改日志.不同的修改操作,生成的日志类型不同.如果事务提交成功,那么这些日志也一定会存在于redo log缓冲区中,然后redo log缓冲区的这些日志会根据我们配置的innodb_flush_log_at_trx_commit来决定何时刷入磁盘,默认值是1,代表事务提交后刷入磁盘,0代表每隔1s刷入到磁盘,2代表等待操作系统刷入到磁盘.在mysql中,会记录刷新到磁盘的redo log文件的字节数是多少,称为lsn。此外还有个checkpoint lsn,表示redo log文件所记录的对数据的修改已经到达哪个位置.比如说,redo log文件的lsn为1000,checkpoint lsn为900,那么900以前的这些日志对应的数据已经持久化到页中了,因此我们只需要使用lsn为900-1000的redo log日志所记录的对页的修改来恢复数据. 类比如果了解过redis的aof持久化日志,那么这两者有一定的相似之处 参考资料mysql技术内幕-innodb存储引擎 7.2.1 redo","categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}],"author":"君霖"},{"title":"CDN原理","slug":"CDN原理","date":"2023-12-05T08:11:00.000Z","updated":"2024-04-05T14:29:24.123Z","comments":true,"path":"2023/12/05/CDN原理/","link":"","permalink":"http://example.com/2023/12/05/CDN%E5%8E%9F%E7%90%86/","excerpt":"","text":"为什么要有CDN如果没有CDN,那么视频将直接存储在数据中心中.这将带来三个问题: 数据中心如果离用户过远,那么中间必然会经过很多链路,如果某个链路的传输速率小于视频消费速率,那么整体的视频消费速率就会下降. 数据中心不得不重复发送一些热点视频,这样浪费带宽,并且这些视频的发送需要向ISP进行付费. 数据中心可能会出现单点故障问题. CDN部署策略 Enter Deep.部署CDN集群到ISP的访问网络,目的是更加靠近用户,因此可以减少链路和路由器的数量,最终降低用户感知的延迟,提升吞吐量.这种部署方式由于采用的是高度分布式设计,因此维护和管理集群的任务比较有挑战性 Bring Home.将CDN放置在互联网交换点中(IXP),这种部署方式对于用户的延迟会比较高,吞吐量也会降低,但是维护和管理的开销也会比较低 CDN数据拉取方式每个CDN存储的数据基本都不一样,因为有些数据对于其它地区来说不是热门数据,CDN使用的是简单的拉取策略,如果一个客户从CDN中没有获取到数据,那么这个CDN将会从数据中心或者集群中的其他CDN中获取,并且将数据缓存到本地,如果数据满了,将会删除掉最不经常请求的数据. CDN原理通常CDN利用DNS来拦截和重定向用户请求,一个典型的流程如下: 客户浏览某个网站,比如www.douyin.com 客户请求某个视频,比如视频地址是www.vedio.douyin.com/7A8W,此时用户主机向其本地DNS获取域名对应的IP地址 本地DNS服务器请求其域名对应的DNS权威服务器获取IP地址,DNS发现其域名中有”vedio”字符串,此时并不返回一个IP地址,而是返回CDN服务器的域名,例如A1235.cdn.com 接下去本地DNS将向A1235.cdn.com对应的DNS权威服务器获取对应的IP.此时该DNS服务器通常会查询地理位置数据库来获取离本地DNS服务器最近的CDN服务器的IP地址,然后将IP地址返回给本地DNS服务器 本地DNS服务器将CDN的IP地址返回给用户主机 用户主机收到IP地址,向对应CDN请求资源 CDN集群选择策略DNS是如何选择集群中的某个CDN的? 地理就近策略通常权威DNS服务器从本地DNS服务器中获取到其IP地址,通过使用商业地理位置数据库获取到离该本地DNS服务器最近的CDN服务器.这种方式对于大部分的用户来说是合理的,但是也存在缺陷.比如: 地理最靠近的CDN服务器并不是网络路径最短的服务器, 有可能用户的本地DNS服务器离用户很遥远. 总是返回同样的CDN服务器给用户,没有考虑网络路径上延迟和可用带宽的变化. 为了解决这个缺陷.可以采用探测技术,来主动感知CDN到客户之间的延迟,从而为CDN的选择提供数据参考. 参考资料计算机网络自顶向下方法 2.6.3 Content Distribution Networks","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"author":"君霖"},{"title":"Java字符串常量池和intern方法解析","slug":"Java字符串常量池和intern方法解析","date":"2023-05-27T17:13:00.000Z","updated":"2024-04-05T04:04:11.997Z","comments":true,"path":"2023/05/28/Java字符串常量池和intern方法解析/","link":"","permalink":"http://example.com/2023/05/28/Java%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0%E5%92%8Cintern%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90/","excerpt":"","text":"这篇文章,来讨论一下Java中的字符串常量池以及Intern方法.这里我们主要讨论的是jdk1.7,jdk1.8版本的实现. 字符串常量池在日常开发中,我们使用字符串非常的频繁,我们经常会写下类似如下的代码: String s = “abc”; String str = s + “def”; 通常,我们一般不会这么写:String s = new String(“jkl”),但其实这么写和上面的写法还是有很多区别的. 先思考一个问题,为什么要有字符串常量池这种概念?原因是字符串常量既然是不变的,那么完全就可以复用它,而不用再重新去浪费空间存储一个完全相同的字符串.字符串常量池是用于存放字符串常量的地方,在Java7和Java8中字符串常量池是堆的一部分. 假如我们有如下代码: 1234String s &#x3D; &quot;abc&quot;;String s1 &#x3D; s + &quot;def&quot;; String s2 &#x3D; new String(&quot;abc&quot;);String s3 &#x3D; new String(&quot;def&quot;); 那么从内存分配的角度上看,最终会有哪些字符串生成呢,首先我先给出一张图来代表最终的结论,然后再分析一下具体的原因: 现在来依次分析上面的代码的执行流程: 执行String s = “abc”,此时遇到”abc”这个字符串常量,会在字符串常量池中完成分配,并且会将引用赋值给s,因此这条语句会在字符串常量池中分配一个”abc”.(这里其实没有空格,是因为生成文章时出现了空格,下文中如果出现同样情况,请忽略空格) 执行String s1 = s + “def”,其实这个语句看似简单,实则另有玄机,它其实最终编译而成的代码是这样的:String s1 = new StringBuilder(“abc”).append(“def”).toString().首先在这个语句中有两个字符串常量:”abc”和”def”,所以在字符串常量池中应该放置”abc”和”def”,但是上个步骤已经有”abc”了,所以只会放置”def”.另外,new StringBuilder(“abc”)这个语句相当于在堆上分配了一个对象,如果是**new**出来的,是在堆上分配字符串,是无法共享字符串常量池里面的字符串的,也就是说分配到堆上的字符串都会有新的内存空间. 最后toString()也是在堆中分配对象(可以从源码中看到这个动作),最终相当于执行了new String(“abcdef”);所以总结起来,这条语句分析起来还是挺麻烦的,它分配了以下对象: 在字符串常量池分配”abc”,但本来就有一个”abc”了,所以不需要分配 在字符串常量池中分配“def” 在堆中分配了”abc”,然后被扩展成”abcdef”,再之后可能被垃圾回收,这个只是临时为了产生String对象而产生的对象 在堆中分配了”abcdef” 执行String s2 = new String(“abc”).首先有个字符串常量”abc”,需要分配到字符串常量池,但是字符串常量池中已经有”abc”了,所以无需分配.因此new String(“abc”)最终在堆上分配了一个”abc”.所以总结起来就是,在堆中分配了一个”abc” 执行String s3 = new String(“def”);.首先有个字符串常量”def”,需要分配到字符串常量池,但是字符串常量池中已经有”def”了,所以无需分配.因此new String(“def”)最终在堆上分配了一个”def”.所以总结起来就是,在堆中分配了一个”def”。 总结起来,全部语句执行后分配的对象如下: 在堆中分配了一个”abc”,两个”abcdef”(其中一个只是为了产生String而临时产生的对象),一个”def” 在字符串常量池中分配了一个”abc”,一个”def” 也就是图中所表示的这些对象,如果明白了对象是如何分配的,我们就可以分析以下代码的结果: 123456789String s = &quot;abc&quot;;String s1 = s + &quot;def&quot;;String s2 = new String(&quot;abc&quot;);String s3 = new String(&quot;def&quot;);String s4 = &quot;abcdef&quot;;String s5 = &quot;abc&quot;;System.out.println(s == s2); //false 前者引用的对象在字符串常量池 后者在堆上System.out.println(s == s5);; //true 都引用了字符串常量池中的&quot;abc&quot;System.out.println(s1 == s4); //false 前者引用的对象在堆上，后者在字符串常量池中 intern方法在字符串对象中,有一个intern方法.在jdk1.7,jdk1.8中,它的定义是如果调用这个方法时,在字符串常量池中有对应的字符串,那么返回字符串常量池中的引用,否则返回调用时相应对象的引用,也就是说intern方法在jdk1.7,jdk1.8中只会复用某个字符串的引用,这个引用可以是对堆内存中字符串中的引用,也可能是对字符串常量池中字符串的引用.这里通过一个例子来说明,假如我们有下面这段代码: 123456String str &#x3D; new String(&quot;abc&quot;);String str2 &#x3D; str.intern();String str3 &#x3D; new StringBuilder(&quot;abc&quot;).append(&quot;def&quot;).toString();String str4 &#x3D; str3.intern();System.out.println(str &#x3D;&#x3D; str2);System.out.println(str3 &#x3D;&#x3D; str4); 那么str2和str以及str3和str4是否相等呢?如果理解了上面对字符串常量池的分析,那么我们可以明白在这段代码中,字符串在内存中是这么分配的: 在堆中分配一个”abc”,一个“abcdef”,一个即将被垃圾回收的”abcdef” 在字符串常量池中分配一个”def”,一个”abc” 当执行String str2 = str.intern();时,会先从字符串常量池中寻找是否有对应的字符串,此时在字符串常量池中有一个”abc”,那么str2就指向字符串常量池中的”abc”,而str是new出来的,指向的是堆中的”abc”,所以str不等于str2; 当执行String str4 = str3.intern();会先从字符串常量池中寻找”abcdef”,此时字符串常量池中并没有”abcdef”,因此str4会指向堆中的”abcdef”,因此str3等于str4,我们会发现一个有意思的地方:如果将第三句改成String str3 = new StringBuilder(“abcdef”).toString();,也就是把append后面的字符串和前面的字符串做一个拼接,那么结果就会变成str3不等于str4.所以这两种写法的区别还是挺大的. 要注意的是,在jdk1.6中intern的定义是如果字符串常量池中没有对应的字符串,那么就在字符串常量池中创建一个字符串,然后返回字符串常量池中的引用,也就是说在jdk1.6中,intern方法返回的对象始终都是指向字符串常量池的.如果上面的代码在jdk1.6中运行,那么就会得到两个false,原因如下: 当执行String str2 = str.intern();时,会先从字符串常量池中寻找是否有对应的字符串,此时在字符串常量池中有一个”abc”,那么str2就指向字符串常量池中的”abc”,而str是new出来的,指向的是堆中的”abc”,所以str不等于str2; 当执行String str4 = str3.intern();会先从字符串常量池中寻找”abcdef”,此时字符串常量池中并没有”abcdef”,因此执行intern方法会在字符串常量池中分配”abcdef”,然后str4最终等于这个字符串的引用,因此str3不等于str4,因为上面的str3指向堆,而str4指向字符串常量池,所以两者一定不会相等. 在深入理解JVM虚拟机一书中,就有类似的代码: 1234String str1 &#x3D; new StringBuilder(&quot;计算机&quot;).append(&quot;软件&quot;).toString();System.out.println(str1 &#x3D;&#x3D; str1.intern());String str2 &#x3D; new StringBuilder(&quot;ja&quot;).append(&quot;va&quot;).toString();System.out.println(str2 &#x3D;&#x3D; str2.intern()); 在jdk1.6中,两个判断都为false.因为str1和str2都指向堆,而intern方法得出来的引用都指向字符串常量池,所以不会相等,和上面叙述的结论是一样的.在jdk1.7中,第一个是true,第二个是false.道理其实也和上述所讲的是一样的,对于第一个语句,最终会在堆上创建一个”计算机软件”的字符串,执行str1.intern()方法时,先在字符串常量池中寻找字符串,但没有找到,所以会直接引用堆上的这个”计算机软件”,因此第一个语句会返回true,因为最终都是指向堆.而对于第三个语句,因为和第一个语句差不多,按理说最终比较也应该返回true.但实际上,str2.intern方法执行的时候,在字符串常量池中是可以找到”java”这个字符串的,这是因为在Java初始化环境去加载类的时候(执行main方法之前),已经有一个叫做”java”的字符串进入了字符串常量池,因此str2.intern方法返回的引用是指向字符串常量池的,所以最终判断的结果是false,因为一个指向堆,一个指向字符串常量池. 总结从上面的分析看来,字符串常量池并不像是那种很简单的概念,要深刻理解字符串常量池,至少需要理解以下几点: 理解字符串会在哪个内存区域存放 理解遇到字符串常量会发生什么 理解new String或者是new StringBuilder产生的对象会在哪里存放 理解字符串拼接操作+最终编译出来的语句是什么样子的 理解toString方法会发生什么 这几点都在本文章中覆盖了,相信理解了这几点之后一定对字符串常量池有一个更深刻的理解.其实这篇文章的编写原因是因为阅读深入理解JVM虚拟机这本书的例子时突然发现作者所说的和我所想的是不一样的,但是书上可能对这方面没有展开叙述,所以我去查了点资料,然后写了一些代码来验证,最终决定写一篇文章来记录一下自己的理解,在编写代码过程中,还发现了一个分析对象内存地址的类库,我放在参考资料中了. 参考资料https://www.baeldung.com/java-object-memory-address 查看java对象内存地址","categories":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"}],"author":"君霖"},{"title":"怎么保证Kafka的消息不丢失","slug":"怎么保证kafka的消息不丢失","date":"2023-05-24T14:16:00.000Z","updated":"2024-04-05T07:15:21.186Z","comments":true,"path":"2023/05/24/怎么保证kafka的消息不丢失/","link":"","permalink":"http://example.com/2023/05/24/%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81kafka%E7%9A%84%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/","excerpt":"","text":"怎么保证Kafka的消息不丢失怎么保证Kafka不丢失消息Kafka保证不丢失消息需要生产者,Broker及消费者之间的协作,任何一个地方没有可靠性的保证,消息就有可能丢失.因此需要在整个链路上进行全盘考虑,使用具体的配置来达到目的 Broker端配置 设置合理的复制因子.Broker可以配置参数replication.factor=N(主题级别,也可以配置Broker级别),配置尽可能大的复制因子意味着分区将会有多个副本,如果副本足够多,那么当一个分区不可用的时候,其它分区就可以接替分区的领导,提高可靠性. 禁用不完全的领导选举.Broker可以配置参数unclean.leader.election.enable=false(Broker级别)来禁用不完全的领导选举,这意味着没有完全进行同步的副本不可以选举成为分区的领导,这样不会造成消息的丢失.另外,如果不进行禁用,那么一个处于同步的分区领导A下线之后,另外一个非同步的分区B成为了领导,那么当A上线时,将强制删除之前收到的消息(B并没有这些消息),改为对分区B进行复制,这样造成了消息的丢失. 设置合理的最小同步副本个数.Broker可以配置参数min.insync.replicas=N(主题级别和Broker级别)来限制最小同步副本的个数.在Kafka中,当消息被写入到所有同步的副本中,才会被认为是已提交的,如果此时的同步副本只有一个,且配置min.insync.replicas=all,那么只要1个同步副本接收到消息,就认为消息时已提交的.为了保证消息写入到多个同步副本中,我们需要设置一个数量,比如min.insync.replicas=N,当生产者写入消息时,如果此时分区没有N个同步的副本,那么此时消息将不会被写入,生产者将接收到NotEnoughReplicasException. 设置合理的心跳超时时间或复制间隔时间. 一个副本被认为不处于同步的情况通常有两种,一种情况是它未能在一定时间内向Zookeeper发送心跳,另外一种情况是在一定时间内未能复制分区领导的消息(或者是在一定时间内未能复制最新的消息).通过配置zookeeper.session.timeout.ms=N,我们可以设置一个合理的心跳超时时间,来减少网络波动或者垃圾回收带来的影响,使得副本变成不同步副本.通过配置replica.lag.time.max.ms,我们可以设置一个合理的复制间隔时间,来使得副本不那么容易变成不同步副本. 设置合理的持久化消息大小阈值或者持久化时间间隔.Kafka认为消息是提交的并不需要消息被真正写入到磁盘,因为Kafka认为它的机制已经足够可靠,即使消息没有刷到磁盘中.但是为了进一步提高可靠性,可以通过配置flush.messages,设置一个合理的刷新到磁盘的消息大小数,来保证消息及时刷新到磁盘中.也可以通过配置flush.ms,设置一个合理的刷新到磁盘的时间间隔,保证消息及时刷新到磁盘. 生产者端配置 将ack设置为一个合理的值.ack的值代表有多少副本接收到消息,生产者才会收到正确的响应,ack等于0意味着消息被传到网络上,生产者就认为是成功.如果ack=1,就代表一个broker接到消息就认为是成功.将ack=all与min.insync.replicas=N参数结合,可以保证有N个副本收到了消息,此时Broker向生产者返回ack. 配置合理的重试参数进行重试.对于Broker返回的可重试的错误,生产者应该进行重试来保证消息不丢失.可以使用默认的最大重试次数(一直重试)配合最大的发送超时时间参数delivery.timout.ms,来保证在超时时间内消息不断进行重试. 对于不可重试错误,开发者需要修改配置解决. 消费者端配置 最好使用auto.offset.reset=earliest.当消费者消费一个分区时,如果没能获取到上一次同一个消费者组消费该分区的偏移量,那么将采用设置的自动偏移重置参数所配置的策略来重新获取消息,使用earliest虽然可能导致消息被重复消费,但是可以最大限度的保证消息不丢失 最好使用手动提交,自动提交有可能提交一些程序还没有处理过的偏移量,使用手动提交会更灵活. 成功处理完消息之后再提交偏移量. 考虑对分区重平衡进行恰当的处理.分区重平衡时,应该要保证分区在收回之前成功提交偏移量 在处理消息失败时进行恰当的处理.当我们在处理消息时发生错误,第一种方式可以使用pause方法暂停在轮询中获取数据,然后重试去处理发生错误的消息.第二种方式可以将发生错误的消息写入到另外一个主题中,然后用另外一个消费者组去单独处理. 参考资料 Kafka权威指南第二版第七章 Reliable Data Delivery","categories":[{"name":"kafka","slug":"kafka","permalink":"http://example.com/categories/kafka/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://example.com/tags/kafka/"}],"author":"君霖"},{"title":"为什么Mysql使用B+树来实现索引","slug":"为什么Mysql使用B+树来实现索引","date":"2023-05-20T05:16:00.000Z","updated":"2024-04-05T14:30:05.506Z","comments":true,"path":"2023/05/20/为什么Mysql使用B+树来实现索引/","link":"","permalink":"http://example.com/2023/05/20/%E4%B8%BA%E4%BB%80%E4%B9%88Mysql%E4%BD%BF%E7%94%A8B+%E6%A0%91%E6%9D%A5%E5%AE%9E%E7%8E%B0%E7%B4%A2%E5%BC%95/","excerpt":"","text":"为什么Mysql使用B+树来实现索引这篇文章,主要来探讨一下为什么Mysql使用B+树来实现索引,这里讨论的目标是Mysql的InnoDB存储引擎.可以想象一下,如果你是Mysql的开发人员,你会怎么去选择合适的数据结构呢? 从实际场景出发任何数据结构都是为了解决特定问题而产生的,那么如果一个用户使用Mysql,通常会有哪些需求呢?我们可以很容易的想到最简单的需求: 通过id或者其他列值进行匹配查询 通过id进行范围查询 用户肯定希望查询的性能越高越好,对于一个表来说,如果能直接通过索引来查询到数据,不必进行全表扫描,那就再好不过了. 选择合适的数据结构这个时候,Mysql的开发人员就会为了解决用户的查询性能问题,开始选择合适的数据结构.能想到的备选方案可能有Hash,B Tree,B+ Tree这三种数据结构. 如果使用Hash作为索引的数据结构Hash能提供O(1)的查询复杂度,对于类似于select * from t where id = 3这种等值匹配来说,性能相当的高,可以说无人能及.但是对于范围查询来说,Hash就有点捉襟见肘了,Hash没办法做到用O(1)的复杂度来进行范围查询,因为这点,Hash是不适合作为底层索引的实现的. 使用B Tree还是B+ Tree那么可选的方案现在只剩下B Tree和B+ Tree.因为这两者的数据结构有点相似,所以在这两个数据结构之间进行选择时,最好是将两者放在一起对比,才能更清楚的知道哪种才是更好的数据结构,. 首先我们应该清楚B树是如何存储数据的.这里给出一张图片: 我们现在以聚簇索引来举例,图中的数字代表主键值,后面的*代表该位置是存放实际的行数据的.每个节点的左指针指向下一级的节点,并且左边指向的节点的主键值大小比上一级的小,右边指向的节点的主键值比上一级的大.B Tree的一个重要特点是在每一个节点都存储了完整的行数据. B+ Tree存储数据的方式是这样的: B+ Tree的重要特点是: 只有叶子节点才会存放整行数据,而非叶子节点只存储主键值,用于向下搜索 叶子节点冗余了所有的主键值,并存储行数据,并且每个节点之间用双向链表进行连接 在图中的12这个节点中,后面是指向24这个节点的,在图中被省略了. 在这里,我们再强调一下B Tree和B+ Tree的重要区别: B Tree的每个节点都存储行数据,而B+ Tree只有叶子节点存放行数据. B Tree因为每个节点都存储行数据,所以没有必要在非叶子节点再冗余任何数据.B+ Tree因为只有叶子节点存储行数据,所以需要在最后一层冗余所有的主键值,并存储行数据,且节点之间用链表进行连接. 理解了这两者的区别之后,我们来考虑一下针对实际场景,哪个数据结构才是更好的选择.首先,我们考虑一下等值查询,对于B Tree来说,从根节点的主键值开始进行比较,根据左小右大的特点,可以在某个层级定位到整行数据并返回.对于B+ Tree来说,也是从根节点开始进行比较,不过最终必须定位到叶子节点才能获取到需要的数据.所以在等值查询这个场景下,B Tree看起来比B+ Tree来得好. 那么考虑一下范围查询,比如B Tree来说,查询数据跟等值查询的模式差不多,只不过需要扫描到多个层级的节点.举个例子,如果在上图中寻找主键大于等于10且小于等于24的行数据. 首先从根节点12开始,12是满足条件的,所以获取它的行数据,12后面的同级节点24也符合要求,所以也获取它的行数据. 从12的左指针找到下一个节点,第一个节点是8,不符合要求,之后向后找到它的同级节点10,符合要求,后面没有其他节点了,结束. 节点12的右指针(节点24的左指针)没有指向任何数据,所以无需再找到下一个节点,所有可能的节点都查询过了,查询结束. 我们可以从这个过程中看到,范围查询需要从根节点出发,然后可能要找到它的下一级节点,直到找到所有符合的数据. 对于B+ Tree来说,寻找主键大于等于10且小于等于24的行数据的流程是这样的: 从根节点12向左找到下一级的10这个节点,从10的左指针找到10所在的叶子节点,因为叶子节点是链表结构,那么可以从这个叶子节点的指针一直往后定位到24这个节点,然后返回这中间的所有数据. 实际上数据最终都是存储到磁盘上的,对于Mysql来说,以页为最小单位来读取数据,在上面的图中,我们可以理解成每一个大的长方形框是一个页,而每个页里面存放了很多节点,对于B Tree来说,每个页的节点都存放整行数据,对于B+ Tree来说,非叶子页的节点只存放id,也被称为索引页，而叶子节点存放整行数据.对于页的读取,就涉及到IO操作,要知道IO读取数据的速度比从内存读取数据要慢得多,通常读取页的时间在10ms左右. 以范围查询为例,我们从IO的角度来比较一下B Tree和B+ Tree的区别.对于B Tree而言,读取根节点需要一次IO操作,加载出页之后,当前页的数据可能只有部分符合要求,然后根据页的指针再进行IO操作,找到另外的页,整个过程需要更多的IO操作,并且因为每次读取的页并不是所有数据都满足要求,所以这种方式被称为随机IO.那么对于B+ Tree而言,也需要从根节点向下查询,这其中也涉及到随机IO,但定位到需要的叶子节点后,读取页时只需要根据链表来定位到下一个页,每次读取的页大概率都是符合要求的数据,这种方式被称为顺序IO.所以在范围查询中,B Tree需要更多的IO操作,这样就需要耗费更多的时间.如果对随机IO和顺序IO不是很理解,文末有个参考资料可以去看一下. 所以整体上来看,B+ Tree是更好的选择. 参考资料 https://www.baeldung.com/cs/b-trees-vs-btrees (b树和b+树的区别) https://www.sobyte.net/post/2021-12/whys-the-design-mysql-b-plus-tree/ (为什么mysql使用b+树) https://flashdba.com/2013/04/15/understanding-io-random-vs-sequential/ (顺序IO和随机IO的区别)","categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]},{"title":"五种IO模型","slug":"五种IO模型","date":"2023-05-20T05:05:00.000Z","updated":"2024-04-05T07:15:40.615Z","comments":true,"path":"2023/05/20/五种IO模型/","link":"","permalink":"http://example.com/2023/05/20/%E4%BA%94%E7%A7%8DIO%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"IO的基本操作IO通常涉及两个步骤: 等待数据准备就绪 将数据从内核中复制到进程中 阻塞式IO进程发出recvfrom这个系统调用,进入阻塞状态,直到数据准备就绪并复制到我们的应用缓冲区中.阻塞式IO的特点是IO涉及的两个阶段中,进程都是阻塞的 非阻塞式IO进程轮询发出recvfrom这个系统调用,如果数据没有准备好,系统返回一个错误信息,如果数据准备好,则将数据从内核复制到我们的应用缓冲区中.非阻塞式IO的特点是一阶段进程是非阻塞的,二阶段进程是阻塞的. IO多路复用进程执行select/epoll来监听多个文件描述符,此时进程进入阻塞状态.如果有其中一个文件描述符可读,那么select/epoll就会返回.接着进程向可读的文件发出recvfrom系统调用,进入阻塞状态,将数据从内核复制到我们的应用缓冲区中.IO多路复用的特点是一阶段是阻塞的,但是可以监听多个文件描述符,一旦监听到有数据产生,我们可以选择是否进入二阶段,如果进入二阶段,那么进程将进入阻塞状态. 信号驱动IO 进程注册一个信号处理器并发出一个sigaction系统调用,内核接收到这个调用后返回,这个过程是非阻塞的.当数据准备就绪,内核发出一个 SIGIO信号到我们的信号处理器来告知数据准备就绪.接着进程发出一个recvfrom系统调用,进入阻塞状态,等待数据从内核复制到我们的应用缓冲区中,或者也可以让信号处理器发出一个recvfrom系统调用,将数据从内核复制到我们的应用缓冲区中,之后通知进程来读取数据.这个模型的优点是我们不必等待数据就绪,而是等待收到一个信号,再决定是否进入阻塞状态去获取数据. 异步IO 进程向内核发出一个aio_read调用,并告诉内核如何通知我们,这个过程不会发生阻塞.当数据从内核复制到我们的应用缓冲区完成后,内核再通知我们处理数据.信号驱动IO和异步IO的区别是:前者是数据可以准备读取了通知进程,后者是数据读取完成了通知进程. 五种IO模型的比较 五种IO模型中,前四个模型的二阶段都是阻塞的. 同步IO和异步IO 同步IO意味着进程在请求IO时可能发生阻塞,异步IO意味着进程在请求IO时不会发生阻塞,除了异步IO全流程不会发生阻塞,所以是异步IO.其它IO模型进行IO调用(recvfrom调用)都会发生阻塞,所以是同步IO. 参考资料 Unix网络编程卷1 6.2 I/O Models","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"author":"君霖"},{"title":"HTTP的演变","slug":"HTTP的演变","date":"2023-04-25T08:07:00.000Z","updated":"2024-04-05T14:33:02.928Z","comments":true,"path":"2023/04/25/HTTP的演变/","link":"","permalink":"http://example.com/2023/04/25/HTTP%E7%9A%84%E6%BC%94%E5%8F%98/","excerpt":"","text":"万维网的四个部分 一个文件格式去代表超文本文档——HTML 一个简单的协议去交换这些文档——HTTP 一个客户端去展示和编辑这些文档——浏览器 一个服务器用于访问这些文档 HTTP0.9——一行协议HTTP0.9极其的简单,请求只包含单行,并且只可能使用一个GET方法,后面跟随路径和资源名,一旦连接到服务器之后,协议,服务器,端口号是不需要的,因此请求中没有URL 1GET &#x2F;mypage.html 响应也是极其简单的,只包含响应内容 123&lt;html&gt; A very simple HTML page&lt;/html&gt; 由于HTTP0.9没有HTTP头部,所以只能传输HTML文件.由于没有状态码和错误码,如果出现了任何问题,那么一个特定的HTML文件将生成,来展示问题的描述信息. HTTP1.0——构建扩展性 每个请求添加了版本信息,如GET 资源 HTTP/1.0 响应的开头包含了响应码行,这允许浏览器去识别请求成功或者失败,并由此适配出合适的行为,比如在成功的时候更新资源,在失败的时候使用本地缓存. HTTP头部的概念引入到请求和响应.元数据可以被传输,因此协议变得极其灵活和可扩展. 由于有了Content-Type头部,除了HTML之外的其他类型资源也可以传输. HTTP的请求和响应如下: 1234567891011GET /mypage.html HTTP/1.0User-Agent: NCSA_Mosaic/2.0 (Windows 3.1)200 OKDate: Tue, 15 Nov 1994 08:12:31 GMTServer: CERN/3.0 libwww/2.17Content-Type: text/html&lt;HTML&gt;A page with an image &lt;IMG SRC=&quot;/myimage.gif&quot;&gt;&lt;/HTML&gt; 随后发生的请求和响应: 12345678GET /myimage.gif HTTP/1.0User-Agent: NCSA_Mosaic/2.0 (Windows 3.1)200 OKDate: Tue, 15 Nov 1994 08:12:32 GMTServer: CERN/3.0 libwww/2.17Content-Type: text/gif(image content) HTTP1.1——标准协议HTTP1.1提供了许多改进. 一个连接可以被复用,用于节省时间.在请求资源时,不需要再建立多个连接 管道化.允许在第一个请求还没有完成传输时发送第二个请求,这个降低了通讯的延迟 支持大块的响应 引入了额外的缓存控制机制 客户端和服务器支持内容协商,包括语言,编码,类型的协商. 新增了Host头部,使得一个服务器(一个IP)可以拥有不同的域名. 一个典型的HTTP1.1请求示例,所有的请求都通过一个TCP连接: 1234567891011121314151617181920212223242526272829303132333435363738394041GET /en-US/docs/Glossary/Simple_header HTTP/1.1Host: developer.mozilla.orgUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: en-US,en;q=0.5Accept-Encoding: gzip, deflate, brReferer: https://developer.mozilla.org/en-US/docs/Glossary/Simple_header200 OKConnection: Keep-AliveContent-Encoding: gzipContent-Type: text/html; charset=utf-8Date: Wed, 20 Jul 2016 10:55:30 GMTEtag: &quot;547fa7e369ef56031dd3bff2ace9fc0832eb251a&quot;Keep-Alive: timeout=5, max=1000Last-Modified: Tue, 19 Jul 2016 00:59:33 GMTServer: ApacheTransfer-Encoding: chunkedVary: Cookie, Accept-Encoding(content)GET /static/img/header-background.png HTTP/1.1Host: developer.mozilla.orgUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0Accept: */*Accept-Language: en-US,en;q=0.5Accept-Encoding: gzip, deflate, brReferer: https://developer.mozilla.org/en-US/docs/Glossary/Simple_header200 OKAge: 9578461Cache-Control: public, max-age=315360000Connection: keep-aliveContent-Length: 3077Content-Type: image/pngDate: Thu, 31 Mar 2016 13:34:46 GMTLast-Modified: Wed, 21 Oct 2015 18:27:50 GMTServer: Apache(image content of 3077 bytes) HTTPS1994年网景公司在TCP/IP栈上的顶部创造了一个额外的加密层——SSL.SSL1.0没有公开,而SSL2.0和它的后继者SSL3.0用于电子商务网站的建立.HTTPS加密信息,保证它们在客户和服务器之间的真实性,SSL最终标准化并演变成了TLS.随后,由于互联网的普及性,HTTPS不再只用于电子商务场景中,比如用于私人信息的保护,比如电话簿,用户位置,邮箱等. HTTP2.0——用于提升性能HTTP2.0和HTTP1.1的不同之处: HTTP2.0是一个二进制协议而不是文本协议.它不可以被手动读取和创造.它允许优化提升技术的实现 HTTP2.0是一个多路复用协议.并行请求可以在同一个连接上被创建. HTTP2.0进行了头部压缩.由于一些请求经常发送一些相同的头部信息,这个特性减少了传输重复数据的开销 HTTP2.0允许服务器推送数据到客户端客户端缓存. HTTP3.0——在QUIC上的HTTP下一个主要的HTTP版本,HTTP3与早期的HTTP有相同的语义,但是使用QUIC代替TCP来做运输层传输.QUIC使得HTTP连接拥有更低的延迟,和HTTP2一样,它是一个多路复用协议,但是HTTP2运行在单个TCP连接上,因此包丢失检测和重传处理可能阻塞连接上的所有流.而QUIC运行多个流在UDP之上,并且为每个流实现了单独的包丢失检测和重传,一旦错误发生,只有发生错误的流的数据包会发生阻塞. 参考资料https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"author":"君霖"},{"title":"TCP连接管理","slug":"TCP连接管理","date":"2023-04-25T08:05:00.000Z","updated":"2024-04-05T08:09:44.654Z","comments":true,"path":"2023/04/25/TCP连接管理/","link":"","permalink":"http://example.com/2023/04/25/TCP%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86/","excerpt":"","text":"三次握手具体流程 客户端发送一个SYN报文,SYN=1,随机生成一个序列号client_isn放入序列号字段. 服务端接收SYN报文后,向客户端发送一个SYN-ACK报文,SYN=1,ack=client_isn+1放入ACK字段,随机生成一个序列号server_isn放入序列号字段. 客户端接收服务端的SYN-ACK报文后,向服务端发送一个ACK报文,SYN=0,ack=server_isn+1 为什么需要三次握手,而不是两次握手TCP是全双工通信,客户端和服务端都需要根据对方的序列号来记录数据的接收情况,所以在建立连接时需要互相告知起始序列号.本来的通信过程是这样的: A-&gt;B SYN B-&gt;A ACK B-&gt;A SYN A-&gt;B ACK 由于第2步和第3步都是B发送给A,并且TCP报文头部允许SYN和ACK的共存,所以可以把这两步合成一步,最终形成了三次握手. 四次挥手流程 当客户端没有数据可以发送,客户端发送一个FIN报文给服务端,然后进入FIN_WAIT_1状态 服务端接收FIN报文,进入CLOSE_WAIT状态,并返回一个ACK消息给客户端,当客户端接收到ACK,进入FIN_WAIT2状态 当服务端没有数据可以发送,服务端发送一个FIN报文给客户端 客户端接收FIN报文,然后发送一个ACK消息给服务器并进入TIME_WAIT状态,服务器接收到ACK消息后进入CLOSED状态. 客户端等待2个最大段存活时间后,进入CLOSED状态 四次挥手中timewait的作用 TCP使用序列号来唯一的标识数据.如果一个服务器向客户端传递数据,但客户端还没有收到数据.但此时连接关闭了.如果有另外一个新的连接使用同样源地址,源端口号和目标地址,目标端口号连接上服务器,并且收到了上次那个服务器返回的数据,但其实这个数据是无效的,那么就会可能导致客户端获取到错误的数据.使用timewait,那么收到这个错误的数据时,这个数据已经至少经历了2个最大段存活时间(Max Segment Lifetime),那么认为这个数据是无效的,进而丢弃这个消息,最终保证了数据传输的正确性.. 客户端如果返回给服务器的ACK丢失了,那么服务器会认为当前连接还没有正常关闭.如果有另外一个连接使用了同样源地址,源端口号和目标地址,目标端口号和服务器进行三次握手,由于服务端认为连接没有结束,就会返回RST响应,进而握手过程结束.通过使用timewait可以等待服务端重新发送FIN,然后再重新进行ACK. 参考资料 https://www.sobyte.net/post/2021-12/whys-the-design-tcp-time-wait/) https://networkengineering.stackexchange.com/questions/24068/why-do-we-need-a-3-way-handshake-why-not-just-2-way 计算机网络自顶向下方法 3.5.6 TCP Connection Management","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"DNS原理","slug":"DNS原理","date":"2023-04-12T08:06:00.000Z","updated":"2024-04-05T08:10:06.725Z","comments":true,"path":"2023/04/12/DNS原理/","link":"","permalink":"http://example.com/2023/04/12/DNS%E5%8E%9F%E7%90%86/","excerpt":"","text":"什么是DNSDNS是一个在DNS服务器层次上实现的分布式数据库,是一个应用层协议,允许主机去查询这个分布式数据库.DNS服务器通常是一个运行Berkley互联网域名(BIND)软件的UNIX机器.DNS运行在UDP之上,并使用53号端口. DNS的作用 完成主机名到IP地址的转换 实现主机别名.主机名可以有多个,其中一个叫做权威主机名,其余的叫做主机别名,可以通过主机别名或者IP地址获取权威主机名 IP负载均衡.一个主机名可以关联多个IP地址,客户端根据主机名从DNS服务器中获取到IP地址列表,DNS通常会以列表的第一个IP地址作为最终结果.为了让第一个IP地址更加具有分布性,DNS服务器会对列表进行打乱后返回. DNS服务器种类 根DNS服务器.通过传递顶级域名(如com,org)请求根DNS服务器,可以找到处理对应主机名的顶级域名DNS服务器 顶级域名DNS服务器.通过传递权威域名(如facebook.com),可以找到处理对应主机名的权威DNS服务器 权威DNS服务器.在互联网上可以直接访问的服务器必须要有域名到地址的映射,权威DNS服务器用于保存这些映射. 本地DNS服务器.靠近用户的DNS服务器,本质上不属于DNS服务器层次.DNS解析请求通常先发送给本地DNS服务器,再由本地服务器转发到DNS服务器层次结构上,本地DNS服务器在这里充当代理. DNS解析流程(典型方式) 客户端请求本地DNS服务器获得www.baidu.com对应的IP地址 本地DNS服务器请求根DNS服务器获取处理com的顶级域名DNS服务器的IP地址 本地DNS服务器获得根DNS服务器返回的顶级域名DNS服务器的IP地址 本地DNS服务器请求顶级域名DNS服务器获取处理baidu.com的权威DNS服务器的IP地址 本地DNS服务器获得顶级域名DNS服务器返回的权威DNS服务器的IP地址 本地DNS服务器请求权威服务器获取处理www.baidu.com对应的IP地址 本地DNS服务器获得权威服务器返回的IP地址 本地DNS服务器向客户端响应最终获得的IP地址 DNS缓存的作用DNS缓存通常存放于本地DNS服务器中,当本地DNS服务器获取到某个主机名到IP的映射关系后,可以选择将其缓存起来,并设置一个过期时间(比如两天),这样当有另外的客户端请求相同主机名的IP地址时,就不用走完整的DNS解析流程,这样可以提高性能,减少延迟. 参考资料计算机网络自定向下方法2.4.1 Services Provided by DNS 2.4.2 Overview of How DNS Works","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"author":"君霖"},{"title":"页分裂和页合并","slug":"页分裂和页合并","date":"2023-04-12T07:55:00.000Z","updated":"2024-04-05T08:49:30.206Z","comments":true,"path":"2023/04/12/页分裂和页合并/","link":"","permalink":"http://example.com/2023/04/12/%E9%A1%B5%E5%88%86%E8%A3%82%E5%92%8C%E9%A1%B5%E5%90%88%E5%B9%B6/","excerpt":"","text":"mysql表数据组成一个表通常由一个.ibd文件所表示,一个文件又由N个段组成,每个段关联一个索引.一个段又由多个区组成,而每个区又由多个页组成,默认情况下,区的大小为1MB,页的大小为16KB,一个区中最多可以存放64个页.一个页至少需要存放两行数据,因此页中的行数据的长度最长为8KB,而每行数据有多大,由表的模式所决定,通常表的模式又由一个.frm文件所表示.一张图片可以更形象的表达一些概念: 页的组成Mysql中操作数据的最小单位不是行,而是页,这意味着Mysql不会单独从磁盘上查询一行记录,而是至少查到一个页,然后从中获取行记录.在主键索引的叶子节点中,数据将按照主键大小按顺序存放在页中,页和页之间通过双向链表进行连接,这也就意味着在物理上相邻的两个页不一定是按顺序的.我们所讨论的页分裂和页合并中的”页”具体指的就是主键索引的叶子节点. 页的内部一个具体的页的样子如下图,主键ID依次为1,2,3,4,通常页中有一个50%的阈值用于合并操作,也就是页大小的一半. 数据将按顺序插入页中: 如果数据无法存放在当前页,那么将存放在下一个页中 页合并如果页中的数据被删除,那么实际上这块的空间并不会被回收,而是标记为可重复利用.当一个页的数据被删除或者更新,空间小于所规定的阈值大小,那么Mysql会查找前一个页,和后一个页,判断是否可以将这个页合并到另外一个页,这样就可以节省下一个页的空间.以下是Page5和Page6的一个合并过程: Page5的一些数据被删除,并且空间降到了阈值之下 Page5的下一个页Page6的数据此时不到一半,并且这些数据可以放入Page5 进行页合并操作 Page6变成了空页,用于存放新的数据 页分裂如果一个页快满了,此时我们插入数据,但下一个页的空间也全部占满.这个时候Mysql将创建一个新页,然后将快满的这个页的部分数据迁移到新页中,这部分数据就是超出原来那个页阈值的那部分数据,之后再插入新的数据.以下是一个页分裂过程: 往Page10插入数据,但此时该页已没有空间可以容纳 Page10的下一个页Page11也没有空间可以容纳,并且27这个数据是要插入到28之前的. 此时创建一个新页Page12,将Page10的24-26号数据迁移到新页,并插入27 修改页之间的链接关系,Page10的下一个页此时是Page12而不是Page11,因此页并不是物理连续的,而是逻辑连续的.两个相邻的页可能存放在不同的区中. 索引设计带来的影响假如我们有个主键,如果我们使用自增id,那么产生的页分裂和页合并会比较少,但是如果我们使用无规则的id,那么大概率会使得整个数据分布得很稀疏,进而给性能带来以下影响: 使用了更多的页,浪费更多的磁盘空间 数据分布在很多稀疏的页中,加载页也需要CPU时间,那么可能导致获取数据时间变长 页合并和页分裂进行过程会带来性能影响 参考资料https://www.percona.com/blog/innodb-page-merging-and-page-splitting/","categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}],"author":"君霖"},{"title":"select,poll,epoll","slug":"select,poll,epoll","date":"2023-04-08T07:54:00.000Z","updated":"2024-04-05T07:54:31.143Z","comments":true,"path":"2023/04/08/select,poll,epoll/","link":"","permalink":"http://example.com/2023/04/08/select,poll,epoll/","excerpt":"","text":"什么是select12int select(int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timeval *timeout); maxfdp1:select函数需要传入程序监听的最大的文件描述符+1的值 readset,writeset,exceptset:读,写,异常文件描述符数组,通常是int数组,例如数组的每个元素占64位,第一个int数的各个位代表0-63号文件描述符,第二个数代表64-127,如果位为0,则表示不监听,如果位为1,则代表监听.该数组是一种value-result的形式,也就是我们将感兴趣的文件描述符传入进去,如果文件描述符处于就绪状态,那么结果也是在这个数组体现.内核只能从set中从头遍历才能知道我们要监听哪些文件描述符.调用方需要主动传入maxfdp1可以让内核知道判断到哪个位之前结束,也就是客户所需要的文件描述符的最大值,内核不会判断超出这个数字的其他描述符. 1234struct timeval &#123; long tv_sec; /* seconds */ long tv_usec; /* microseconds */ &#125;; timeval:超时参数 一直等待:如果调用select时不传入这个参数,则代表只有当描述符可以准备进行IO,select才返回. 等待固定时间:如果传入参数且时间步为0,表示如果超出这个时间,则不再等待文件描述符处于准备状态. 立即返回:传入参数,但时间设置成0,表示调用函数去检查是否描述符可用,检查完之后函数会立即返回,这种方式被称作轮询. 返回值: 正常情况:readset,writeset,exceptset中打开的位数量的总和,函数返回后,我们需要再次遍历各个集合,如果位被设置为1,则代表描述符可用. 0:代表超时 -1:代表发生错误 什么是poll1int poll(struct pollfd *fdarray, unsigned long nfds, int timeout); fdarray:监听的描述符结构体数组 nfds:监听的描述符数量 timeout:超时参数 返回值为可用的文件描述符数量,既revents累加的所有发生的事件的总量.此时我们需要遍历nfds个文件描述符去判断某个文件描述符是否可用.这里不像select的位图实现,而是明确传入一个结构,内核可以直接遍历去判断,并且内核判断的结果在revents上面体现,这种方式比起select已经把值和结果分开了. 12345struct pollfd &#123;int fd; //要检查的描述符short events; //感兴趣的事件short revents; //实际发生的事件&#125;; 我们需要要检查的描述符传入到poll中,具体events和revents如何表示可读,可写,异常情况由具体的实现声明. epollepoll的运行流程 使用epoll在内核空间创建了epoll实例 我们可以通过epoll_ctl去添加自己感兴趣的文件描述符,称为interest_list,这个支持我们动态的去添加描述符. 如果epoll实例发现任何感兴趣的文件描述符变得可用,然后把这些文件描述符放入一个称为ready_list的结构, 当我们调用epoll_wait去获取可用的描述符时,如果ready_list不为空,那么就会将可用的文件描述符立即返回,此时可以通过文件描述符去获取数据 我们只需要注册好epoll实例,之后再去获取可用的描述符,这个过程不像select和poll一样是异步的. select,poll,epoll的区别 select和poll的区别是select通过位图传递监听的描述符,而poll直接传递结构来监听描述符 select和poll每次获取可用的描述符时,都需要传入监听的描述符列表,并且每次进程都得扫描哪些描述符可用. 而epoll通过epoll实例进行注册,获取可用的描述符列表时,不需要再传入监听的描述符列表,并且进程可以直接从epoll实例获取到哪些描述符可用.select和poll采用的是多路复用模型,而epoll采用的更像是事件驱动IO模型.epoll还可以动态的添加想要监听的描述符,而select,poll需要修改参数去重新调用. 参考资料 Unix网络编程6.3 select Function Unix网络编程6.10 poll Function https://medium.com/@avocadi/what-is-epoll-9bbc74272f7c https://man7.org/linux/man-pages/man7/epoll.7.html","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"author":"君霖"},{"title":"零拷贝","slug":"零拷贝","date":"2023-04-05T10:23:00.000Z","updated":"2024-04-05T07:24:15.330Z","comments":true,"path":"2023/04/05/零拷贝/","link":"","permalink":"http://example.com/2023/04/05/%E9%9B%B6%E6%8B%B7%E8%B4%9D/","excerpt":"","text":"概念零拷贝意味着数据的传输可以直接使用内核中的缓冲区并且在内核态中完成，无需再回到用户态中使用应用程序缓冲区。 场景读文件然后通过网络发送到另外一个程序 传统方式在java中,传统方式使用如下代码来完成. 12File.read(fileDesc, buf, len); //从磁盘读数据Socket.send(socket, buf, len); //将数据发送到socket 整个流程如下: 程序进行系统调用,从用户态切换到内核态,开始从磁盘读取数据 在磁盘中读取数据并复制到内核的读缓存区中完成后,之后内核态切换到用户态,将数据从内核缓冲区复制到应用缓冲区. 程序进行系统调用,从用户态切换到内核态,将应用缓冲区的数据复制到Socket缓冲区. 在内核态中将Socket缓冲区的数据复制到NIC缓冲区中. 数据传输完成,从内核态切换回用户态. 整个过程涉及用户态和内核态四次上下文切换和四次复制操作.如图所示: 使用零拷贝使用零拷贝技术,可以将传统方式优化成直接将数据从读缓存拷贝到Socket缓存,不需要经过应用缓冲区 在java中可以使用如下代码实现: 1public void transferTo(long position, long count, WritableByteChannel target); 整个流程如下: 程序进行系统调用,从用户态切换到内核态,开始从磁盘读取数据 在磁盘中复制数据到内核的读缓存区中完成,然后再将数据从读缓存区复制到Socket缓存区,最后从Socket缓存区再复制到NIC缓存区 数据传输完成,从内核态切换回用户态. 整个过程经过优化,变成了两次上下文切换和三次复制. 进一步优化如果底层的网络接口卡支持聚合操作,我们可以进一步减少数据的复制次数. 在java中可以使用如下代码实现: 1public void transferTo(long position, long count, WritableByteChannel target); 在去除应用缓存的基础上,使用操作系统支持的聚集操作,可以使得全过程基本不需要进行数据拷贝. 整个流程如下: 程序进行系统调用,从用户态切换到内核态,开始从磁盘读取数据 在磁盘中复制数据到内核的读缓存区中完成,然后再将数据从读缓存区复制到NIC缓存区 数据传输完成,从内核态切换回用户态. 整个步骤设计两次上下文切换和两次复制. 参考资料https://developer.ibm.com/articles/j-zerocopy/","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"author":"君霖"},{"title":"mysql排序实现原理","slug":"mysql排序原理","date":"2023-04-05T08:00:00.000Z","updated":"2024-04-05T08:01:30.932Z","comments":true,"path":"2023/04/05/mysql排序原理/","link":"","permalink":"http://example.com/2023/04/05/mysql%E6%8E%92%E5%BA%8F%E5%8E%9F%E7%90%86/","excerpt":"","text":"mysql排序实现原理全字段排序当我们执行sql语句中的order by来排序时,mysql会分配一个叫做sort buffer的内存空间.进行排序时,可能涉及到回表的动作,从主键索引中拿出需要使用的行数据放入sort buffer,然后再根据行中的某个字段排序,最终返回结果.如果分配的内存不足以放下这些结果,那么就需要磁盘的临时文件来辅助排序,否则可以直接在内存中完成排序.运行流程为: 从主键索引中取出要返回的行数据 根据返回的行数据中的字段进行排序 sort buffer足够,在内存中完成排序,否则使用临时文件辅助排序 将结果返回 如果内存足够,使用全字段排序更好,减少一次回表,也就减少了对磁盘的访问 rowid排序另外mysql提供了一个叫做max_length_for_sort_data的参数,如果我们从行中所需要的数据总长度大于这个参数设置的值,那么一开始可以先取出排序所需要的字段,排序之后,再通过id去主键索引里面拿到行数据,通过这种方式,运行流程变成了: 从主键索引中取出要排序的字段和主键id 根据返回的排序字段进行排序 sort buffer足够,在内存中完成排序,否则使用临时文件辅助排序 使用主键id再到主键索引中拿到行数据 将结果返回 如果内存不够,使用rowid排序更好,但会增加对磁盘的访问 利用索引覆盖在某些场景,根据具体的排序需求,可以直接建立索引并依靠索引的有序性来直接返回结果,这样就可以直接在索引层面上返回结果,无需依赖sort_buffer或者临时文件,这种排序方式在explain语句中的体现是使用了order by,但不会看到using file sort关键字,甚至可以不回到主键索引查询,直接通过辅助索引就可以返回所有数据,这种方式称为索引覆盖,在explain的extra中会出现using index. 参考资料极客时间mysql45讲 16节 order by是如何工作的","categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}],"author":"君霖"},{"title":"索引下推","slug":"索引下推","date":"2023-04-05T07:59:00.000Z","updated":"2024-04-05T07:59:50.827Z","comments":true,"path":"2023/04/05/索引下推/","link":"","permalink":"http://example.com/2023/04/05/%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8/","excerpt":"","text":"什么是索引下推索引下推指的是当我们使用到辅助索引时,如果辅助索引的其他字段能够用于判断where条件是否满足,从而减少回表次数,那么就使用这些字段先进行判断. 假设有个表叫做people,有个辅助索引(zipcode, lastname, firstname),运行下列sql语句 1234SELECT * FROM people WHERE zipcode=&#x27;95054&#x27; AND lastname LIKE &#x27;%etrunia%&#x27; AND address LIKE &#x27;%Main Street%&#x27;; 如果没有索引下推,mysql执行如下流程: 从辅助索引定位zipcode=95054对应的主键id 遍历每一个主键id,到主键索引获取整个行,然后根据lastname和address从主键索引对应的行记录中来判断哪些记录满足要求 如果使用索引下推,可以利用辅助索引的lastname这个字段,执行流程如下: 从辅助索引定位zipcode=95054对应的主键id 先不去主键索引获取整个行,而是先判断辅助索引中的lastname是否满足’lastname LIKE ‘%etrunia%’’,获取满足所有条件的主键id 遍历每一个主键id,到主键索引获取整个行,然后获取满足address条件的记录 这种方式利用了辅助索引,提前过滤需要回表的主键id,减少了回表次数. 参考资料https://dev.mysql.com/doc/refman/8.0/en/index-condition-pushdown-optimization.html","categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}],"author":"君霖"},{"title":"redis哨兵","slug":"Redis哨兵","date":"2023-04-05T07:20:00.000Z","updated":"2024-04-05T07:21:52.925Z","comments":true,"path":"2023/04/05/Redis哨兵/","link":"","permalink":"http://example.com/2023/04/05/Redis%E5%93%A8%E5%85%B5/","excerpt":"","text":"哨兵的作用哨兵用于监视主服务器及主服务器下的从服务器的情况,当主服务器下线时,选择一个从服务器升级为主服务器,来接替下线的主服务器的工作 哨兵如何发现从服务器和其他哨兵发现主服务器下的从服务器哨兵只配置了主服务器的连接信息.哨兵首先会向主服务器创建一个命令连接.每隔10秒,哨兵会向主服务器发送INFO命令,用于获取主服务器的信息.在主服务器返回的信息中,有主服务器本身的信息以及主服务器下所有从服务器的信息,通过这些信息,哨兵就可以发现从服务器.哨兵会创建与从服务器之间的命令连接,通过这个命令连接,哨兵可以主动向从服务器发送INFO命令,进而获取从服务器的最新信息. 发现哨兵除了向主服务器和从服务器创建命令连接之外,哨兵还会向主服务器和从服务器创建订阅连接.哨兵会通过命令连接定期向主服务器和从服务器的频道中发布一条消息.对于主服务器,哨兵发送自身的信息,加上这个主服务器的信息.对于从服务器,哨兵发送自身的信息加上这个从服务器所复制的主服务器的信息.,其他哨兵由于通过订阅连接订阅了同样的频道,那么通过这个频道的消息就能知道其他哨兵的信息以及所监视的主服务器的最新信息.当哨兵知道了其他哨兵的信息之后,就可以互相创建之间的命令连接,之后可以主动发送INFO命令来获取其它哨兵的信息. 主观下线哨兵会每隔1s向主服务器,从服务器及哨兵发送PING命令,如果在down-after-milliseconds毫秒内,没有返回有效回复,那么哨兵会认为对应的服务器处于主观下线状态.由于不同哨兵配置的主观下线时间不同,那么可能存在一个哨兵认为某个服务器处于主观下线状态,但是另外一个哨兵并不认为该服务器处于主观下线状态. 客观下线 当哨兵发现一个主服务器处于主观下线状态,那么哨兵会向其他哨兵发送命令SENTINEL is-master-down-by-addr 征求它对这个主服务器下线状态的看法 当哨兵收到其它哨兵询问某个服务器是否下线的看法时,哨兵会根据传来的ip和port找到对应的服务器,并确定其是否下线(认为其主观下线或者客观下线),然后向询问的哨兵返回响应,如果down_state为1,则表示认为服务器已下线,否则认为服务器未下线. 当哨兵征求完其他哨兵对服务器下线状态的看法后,会统计认为服务器已下线的哨兵的数量,当这个数量大于等于当前哨兵所配置的客观下线所需数量,则哨兵认为该服务器处于客观下线状态 由于不同哨兵配置的客观下线所需数量不同,那么可能存在一个哨兵认为某个服务器为客观下线状态,而另外一个哨兵认为该服务器不处于客观下线状态 领头哨兵选举 哨兵发现一个服务器处于客观下线状态后,会向其他哨兵发出SENTINEL is-master-down-by-addr 来请求其他哨兵将自己作为它的局部领头哨兵. 在一个配置纪元里,一个哨兵只可以将另外一个哨兵作为自己的局部领头哨兵一次,并且规则是先到先得.如果一个哨兵被超过半数的哨兵作为局部领头哨兵,那么该哨兵将成为此次选举的首领,负责对下线的主服务器执行故障转移操作 哨兵如何选出一个新的主服务器 删除从服务器列表中不在线的从服务器 删除最近5秒没有通信过的从服务器 删除所有连接断开超过down-after-milliseconds*10毫秒的从服务器 选出偏移量最接近主服务器的从服务器 将从服务器升级为主服务器 参考资料 Redis设计与实现 16章 哨兵","categories":[{"name":"redis","slug":"redis","permalink":"http://example.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"}],"author":"君霖"},{"title":"Redis复制的原理","slug":"Redis复制原理","date":"2023-04-05T07:14:00.000Z","updated":"2024-04-05T08:30:20.210Z","comments":true,"path":"2023/04/05/Redis复制原理/","link":"","permalink":"http://example.com/2023/04/05/Redis%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/","excerpt":"","text":"Redis复制的原理一次完整同步的过程 同步.同步操作使得从服务器的数据库状态与当前主服务器的数据库状态一致 传播.主服务器会接着处理客户端的命令,此时需要将这些命令传播给从服务器,才能使得数据重新到达一致状态 完整重同步和部分重同步完整重同步指的是从服务器完整的进行一次主服务器上所有数据的复制.部分重同步指的是只对从服务器缺少的数据进行获取. 完整重同步的实现 从服务器发送SYNC命令给主服务器 主服务器执行BGSAVE命令生成一个RDB文件,并使用一个缓冲区记录从生成RDB文件之后的所有写命令 主服务器将RDB文件发送给从服务器,从服务器加载RDB文件,更新到主服务器执行BGSAVE时数据库状态 主服务器将缓冲区中的写命令发送给从服务器,从服务器执行这些写命令,主从数据库达到一致状态 部分重同步的实现新版Redis复制功能中,使用PSYNC来进行数据的同步,具有两种模式,一种是完整重同步,用于处理初次复制的情况,这种模式和SYNC模式完全一样,另外一种是部分重同步,用于处理断线之后复制的情况 部分重同步由三个部分来实现: 复制偏移量.主服务器和从服务器都维护复制偏移量,主服务器传播数据给从服务器后,会将偏移量加上N,从服务器收到数据后,也会将偏移量的值加上N 复制积压缓冲区.复制积压缓冲区由服务器维护的一个固定的FIFO队列实现.当主服务器传播命令时,除了将命令发送给从服务器,也会将命令写入队列中,复制积压缓冲区中的每个字节都会有一个偏移量值.当从服务器断线重新连接到主服务器时,从服务器将会把当前自己的偏移量值发给主服务器,如果偏移量存在于复制积压缓冲区中且从服务器复制的主服务器为本主服务器,那么将执行部分重同步,否则将执行完整重同步. 服务器运行ID.当从服务器首次复制一个主服务器时,主服务器会向从服务器发送自己的服务器标识,从服务器会保存这个标识.当从服务器断线重新去复制主服务器时,会将这个服务器标识发送给主服务器,如果这个标识不是主服务器的标识,那么说明复制的主服务器改变了,只能执行完整重同步操作,否则主服务器根据偏移量是否在复制积压缓冲区来决定执行完整重同步操作或者是部分重同步操作 心跳检测在命令传播阶段,从服务器会以每秒一次的频率,向主服务器发出REPLCONF ACK OFFSET命令,作用如下: 主服务器会记录从服务器上次发送ACK的时间,用lag来表示,用来判断主从服务器之间的连接是否出了问题 辅助实现mini-slave配置,如果某个从服务器的lag太大,那么主服务器可以拒绝客户端传输的写命令 从服务器在ACK中发送偏移量给主服务器,当主服务器发现从服务器的偏移量不等于自己的偏移量,这个时候可能是发生数据丢失了,那么将会从复制积压缓冲区中获取数据,重新发送给从服务器 参考资料Redis设计与实现 第15章 复制","categories":[{"name":"redis","slug":"redis","permalink":"http://example.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"}],"author":"君霖"},{"title":"Springboot自动配置原理","slug":"springboot自动配置原理","date":"2023-04-01T08:02:00.000Z","updated":"2024-04-05T08:33:01.682Z","comments":true,"path":"2023/04/01/springboot自动配置原理/","link":"","permalink":"http://example.com/2023/04/01/springboot%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E5%8E%9F%E7%90%86/","excerpt":"","text":"Springboot自动配置原理条件注解自动配置类中初始化Bean的方法上,使用@Conditional注解结合一个实现了Condition接口matches方法的类,来决定某个Bean是否进行实例化.一个例子如下: 12345@Conditional(SomeCondition.class)@Beanpublic Bean bean() &#123; return new Bean();&#125; SomeCondition是实现了Condition接口的实现类,通过调用其matches方法,可以知道某个条件是true还是false.如果返回true,才进行bean的实例化.在SomeCondition中,什么情况返回true可以玩出非常多的花样,比如可以基于应用的某个配置信息是否存在,类路径下是否存在某个类. Conditional注解除了可以放在@Bean,还可以放在@Component or @Configuration. 配置属性的获取通过注解@PropertySource从指定路径读取,比如读取applicaiton.properties中的属性,启动参数的属性. 1@PropertySource(value = &quot;classpath:application.properties&quot;, ignoreResourceNotFound = true) 在Spring Boot启动时,会在许多位置获取环境变量,application.properties的属性,启动参数等配置信息. META-INF/spring.factories每个Spring Boot项目都依赖org.springframework.boot:spring-boot-autoconfigure这个jar文件,里面的META-INF目录下有个spring.factories文件,里面包含了大量自动配置类的声明.这些自动配置类实际上就是用了大量的@Conditional注解来判断是否某个Bean进行初始化. 高级条件注解Spring Boot提供的Condition接口过于底层,开发人员可能需要实现这个Condition去完成一些Bean的初始化.为了使开发人员更加方便,Spring Boot提供了一些高级条件注解.比如: 1234@ConditionalOnMissingBean(DataSource.class) //如果容器中没有DataSource类,那么返回true@ConditionalOnBean(DataSource.class)//如果容器中有DataSource类,那么返回true@ConditionalOnMissingClass(DataSource.class) //如果类路径下没有DataSource类,那么返回true@ConditionalOnProperty(&quot;my.property&quot;). //如果声明了my.property属性,那么返回true 在大多数情况下,Spring Boot提供的注解已经可以让你不需要写Condition接口的实现. Starter SpringBoot在pom文件中依赖了很多的starter,每个starter中又依赖了很多的第三方库,通过这种方式,快速的将第三方库引入,这样才能做到自动配置. 参考资料https://www.marcobehler.com/guides/spring-boot-autoconfiguration#_autoconfigurations","categories":[{"name":"spring","slug":"spring","permalink":"http://example.com/categories/spring/"}],"tags":[{"name":"spring","slug":"spring","permalink":"http://example.com/tags/spring/"}],"author":"君霖"},{"title":"快速排序图解","slug":"快速排序图解","date":"2022-09-13T19:09:00.000Z","updated":"2024-04-05T07:15:51.707Z","comments":true,"path":"2022/09/14/快速排序图解/","link":"","permalink":"http://example.com/2022/09/14/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E5%9B%BE%E8%A7%A3/","excerpt":"","text":"故事开始了假设有这样一个场景,有个小学生给了你10000个数字,要你在一天之内把这些数字排好序,然后交给他.身为一个程序猿,你想到了排序算法,进而又想到了快速排序.那么快速排序是怎么实现的呢? 既然10000个数字能排序,那么6个数字也能排序,只要6个数字时,运行结果是准确的,那么这个排序算法就能通用任意个数字的排序.假设我们有这么6个数字: 3 7 2 1 4 6 .首先,快速排序要找个基准点,一般是开头的数字,在我们这个例子中是3,然后想办法把3放到数列的中间位置,使得左边的数字比3小,右边的数字比3大,然后再递归3左右两边的数组,继续使用快速排序,最后就能全局排序.所以要搞清楚,有什么办法可以做到我们要的效果.一个可行的方法是这样的:在数组的头部和尾部各放置一个指针,然后让尾巴和3进行比较,如果大于等于3,那么就往左移动,如果碰到了比3大的数,那么就停下来.另外,如果碰到了左边的指针,也要停下来,这说明我们要的效果已经达到了.说这么多,可能还不够直观,我们用图的方式来模拟这个过程. 起初,整个指针的位置是这样的: 指针继续向左移动,6比3大,4也比3大,直到遇到了1,比3小,这个时候右边的指针就停下来,并且在移动过程中并未碰到左边的指针.现在指针的位置是这样的: 同理,左边的指针如果小于等于3,也要向右移动,直到遇到比3大的数,或者遇到了右指针也要停下来.3等于3,向右移动,7大于3,停下来,现在指针的位置是这样的: 此时,我们把两个指针所指的数字交换一下,为什么要交换呢?因为我们要使得左边的数比3小,右边的数比3大,然后就形成了下面这张图: 此时,两个指针还未碰到,但是我们能看到的是:右指针右边的数据全部比3大,左指针左边的数字全部比3小.这是一个很直观的现象. 接着,我们继续移动右指针,这里的7还要和3再比较一次,当然肯定是比3大,所以一定会左移.然后2比3小,右指针又停下来了: 然后左指针用1和3比,肯定要向右移动,然后移动过去时,发现碰到了右指针: 它们撞到一起去了,这个时候我们已经达到了我们的目的,这就是左右指针停下来的一个标志,我们把开头的3和此时这个位置上的2进行一个交换,那么就变成了: 卧槽!我们达到我们的终极目的:使得3左边的数字比3小,右边的数字比3大. 接下来的故事是,保持3这个位置不动,将左边的2,1当成一个数组,右边的7,4,6当成一个数组,然后再重新对每个数组搞两个指针进行移动,切记:撞到了就是成功了.那么我们可以使用递归的方式来做剩余的事情.如果数组只剩下一个元素,那么一定要结束递归,此时的结束条件是i&gt;=j.下面将展示快速排序的代码,也就是模拟我们现在的整个过程. 快速排序代码12345678910111213141516171819202122public static void quickSort(int [] nums,int i,int j) &#123; if(i&gt;=j)&#123; return; &#125; int start = i; int end = j; int basic = nums[i]; while(i &lt; j) &#123; while(i&lt;j &amp;&amp; nums[j] &gt;= basic) &#123; j--; &#125; while(i&lt; j &amp;&amp; nums[i] &lt;= basic) &#123; i++; &#125; if(i&lt;j) &#123; ArrayUtil.swap(nums, i, j); &#125; &#125; ArrayUtil.swap(nums,i,start); quickSort(nums,start,i-1); quickSort(nums,i+1,end); &#125; 首先代码的开始是判断是不是要结束递归,紧接着,搞出两个指针,开始和开头位置的数字进行比较.代码里面始终要判断i&lt;j,因为撞到了就是成功了,无需再进行下去,另外再没撞到之前,如果双方都停下来一次之后,要交换一下所指的数字,这是为了确保右边的数字比开头的数字大,左边的数字比开头的数字小. 然后,如果i和j相遇,那么一次完整的快速排序就结束了,在遇到的地方和开头的数字进行一次交换,接着再进行左右两个数组的排序,如此递归下去,直到排完. 故事的最后你轻轻松松的排完了10000个数字,写下代码的过程只用了59秒,接着你拿起了桌上那瓶95年的可乐喝了一口,顺手掏出了手机,开始刷起了你养了多年的B站号,进入了传说中的工作休息区.","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"TCP拥塞控制","slug":"tcp拥塞控制","date":"2022-04-05T08:05:00.000Z","updated":"2024-04-05T08:50:03.582Z","comments":true,"path":"2022/04/05/tcp拥塞控制/","link":"","permalink":"http://example.com/2022/04/05/tcp%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/","excerpt":"","text":"为什么会发生拥塞 不同连接会共享网络上的路由器,路由器的传输能力有限,导致传输的数据包不得不在链路中排队. 一条链路上有多个路由器,由于某个连接抢占了中间的某个路由器的容量,可能会导致其它连接的数据包在中途某个路由器中丢失,进而引起重传,引起拥塞. 数据包并没有被丢弃,主机在一定时间内没有收到ACK,进行数据包的重传,导致链路变得拥塞.这种情况称为过早超时. 如何感知拥塞 链路拥塞:丢失事件(超时或者接收到三个重复的ACK)暗示拥塞,发送者应该限制发送速率. 链路不拥塞:收到ACK暗示着数据包正确到达目的,发送者应该加快发送速率. TCP如何限制发送速率使用拥塞窗口cwnd,发送速率限制的公式如下:LastByteSent – LastByteAcked 应该小于等于 min{cwnd, rwnd} 具体实现1.慢开始.一开始发送1个MSS,如果正确收到ACK,则进行加倍,发送2个MSS,4个MSS,以此类推.当发生超时事件时,设置一个叫ssthresh的值,等于cwnd的一半,并且重新一轮新的慢开始阶段,如果到达ssthresh,则结束慢开始阶段,进入拥塞避免阶段.另外,如果不是超时,而是收到3个重复的ACK,对于早期的Tahoe算法,如果收到3个重复的ACK,则重新进入慢开始阶段.对于Reno算法,则会让此时的ssthresh窗口先减半,然后加上3个MSS后继续线性增加,这个过程也叫做快恢复. 2.拥塞避免.正确收到一个ACK后,每次只增加一个MSS.如果发生超时事件,让ssthresh的值等于cwnd的一半,重新进入慢开始阶段.另外,如果收到3个重复的ACK,对于早期的Tahoe算法,如果收到3个重复的ACK,则重新进入慢开始阶段.对于Reno算法,则会让此时的ssthresh窗口加上3个MSS后继续线性增加,这个过程也叫做快恢复. 如图所示: 参考资料 计算机网络自顶向下方法3.6.1 The Causes and the Costs of Congestion 3.7.1 Classic TCP Congestion Control","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"author":"君霖"},{"title":"Redis分布式锁","slug":"Redis分布式锁","date":"2021-06-21T03:16:00.000Z","updated":"2024-04-05T04:30:53.589Z","comments":true,"path":"2021/06/21/Redis分布式锁/","link":"","permalink":"http://example.com/2021/06/21/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"分布式锁需要具备的三个基础属性 安全属性:互斥.在任何时间,最多只有一个客户端可以持有锁 活跃属性A:不能够产生死锁.最终总是可能获取到锁,即使持有锁的其它客户端宕机了 活跃属性B:错误容忍.只要大多数的Redis节点处于正常运行状态,客户端可以获取和释放锁 单实例上的实现1SET resource_name my_random_value NX PX 30000 获取锁:使用一个key,和一个唯一标识来设置键,并且只有当key不存在的时候(NX)才能执行成功,这个唯一标识my_random_value必须在所有的客户端上都是唯一的值,以保证释放锁的客户端是获取锁的那个客户端. 释放锁:当释放锁时,使用Lua脚本加上这个唯一标识.告诉Redis只有当key存在并且值是这个唯一标识时,再释放锁.一个Lua脚本的例子如下: 12345if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then return redis.call(&quot;del&quot;,KEYS[1])else return 0end 如果没有使用唯一标识,那么有可能当一个客户端获取到锁,执行一段业务逻辑,但还没执行完锁已经过期了,此时锁被其他客户端获取到,如果原客户端没有使用唯一标识去删除锁,那么会释放了别的客户端获取到的锁. 红锁算法由于单实例可能存在单点故障,为了保证高可用性,需要使用多个独立的Redis实例来实现分布式锁.每个实例上获取分布式锁的模式和单实例的模式是一样的,只不过在这个基础上加了其他一些步骤. 假如有N个独立的Redis实例,获取锁的步骤如下: 获取当前时间 尝试使用同样的key和唯一标识在所有的N个实例上顺序的获取锁.当在每一个实例上获取锁时,使用一个相对于总体的锁释放时间来得很小的超时时间,例如锁的过期时间是10秒,那么超时时间可以是5-50毫秒,一旦获取锁超时,那么就赶紧去下一个实例获取锁.这么做是防止长时间在某个Redis实例上发生长时间的阻塞,如果一个实例不可用,我们应该尽可能的去下一个实例上获取锁. 通过当前时间减去步骤1锁获取到的时间,客户端可以计算为了获取锁使用了多少时间,如果能在半数以上的Redis实例上获取到锁,并且获取锁所使用的时间小于锁的有效时间,那么就认为获取到了锁 如果锁获取到了,那么锁的真实有效时间被认为是锁的过期时间减去获取锁所使用的时间 如果客户端未能获取到锁,那么应该尝试对所有的实例进行锁的释放,即使在某个实例上并没有获取到锁 开启持久化配置每个实例需要使用持久性配置fsync=always,否则某个实例宕机后恢复,那么有可能导致一个分布式锁被两个客户端获取到. 延长锁时间如果在锁过期之前,客户端还未能处理完逻辑,那么可能需要考虑去在获取到Redis锁的实例上去延长锁的时间,具体方式可以通过Lua脚本来完成,如果key和value都是之前获取锁的值,那么就延长时间.如果没有在半数以上的实例上延长成功,那么就视为不成功,更具体的步骤类似于红锁算法中获取锁的步骤. 参考资料 https://redis.io/docs/manual/patterns/distributed-locks/#analysis-of-redlock","categories":[{"name":"redis","slug":"redis","permalink":"http://example.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"}],"author":"John Doe"},{"title":"运营系统介绍","slug":"运营系统介绍","date":"2021-06-13T16:26:00.000Z","updated":"2024-04-05T07:13:13.486Z","comments":true,"path":"2021/06/14/运营系统介绍/","link":"","permalink":"http://example.com/2021/06/14/%E8%BF%90%E8%90%A5%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"运营系统介绍每个公司可能会有这样一个系统,它负责给公司的用户发布一些营销信息,比如通过短信的方式或者通过APP消息的方式来触达用户.那么首先应该要有一个用户标签的概念,用户标签指的是用户的特征,比如用户在最近30天内购买过一个理财产品,通过一个或多个特征,我们可以从一个用户库里面筛选出一部分人出来,我们称它为客群.有了客群,我们还需要营销的信息,比如给用户发短信,发优惠券等各种各样能触达到用户的方式,这类信息叫做触点.最后一点是我们将在什么时候触达用户,这个叫做执行时间.总结起来,运营系统最主要的职责便是在某个时间,向特定的用户发布特定的信息.除此之外,在某一次任务执行完成之后,我们还需要追踪任务的执行情况,以获取最终的运营效果. 功能点当然,每个公司的业务不一样,可能运营系统还会承担其它的一些职责,现在介绍一下我之前参与开发的运营系统的功能.如图: 基础功能这一部分主要是建立用户-角色体系,运营系统主要针对的用户不是大众用户,而是服务于公司内部的运营人员.主要由以下几点组成: 用户 角色 权限 菜单 定时任务 在运营系统中,首先需要有用户来操作,接着会给予用户某个角色,通过角色控制用户的权限,比如用户可以看到什么菜单,做什么操作(菜单权限和接口权限).另外,定时任务主要给开发人员配置定时任务,在某个时间点执行某个任务. 基础配置这一部分主要是服务于任务执行的信息,比如客群和标签,这一部分主要对接公司的大数据部门.当然短信配置和消息配置其实也算是基础配置,但从功能点来分的话,就没把它们放到基础配置里面了.另外运营系统还服务于另外一个广告系统,所以这部分还有其它一些配置功能.主要功能如下: 任务执行相关: 标签:一个表达式,标识用户的某个特征. 客群:标签的组合,最终筛选出一批用户. 广告系统相关: 运营位:运营位对应APP上的某个广告位. 素材:素材也就是广告的内容,一般为图片或者文案. 推广计划:也就是广告,其中会指定广告位置、素材、客群,同时还有其它一些配置,比如推广的时间段,比如指定用户的操作系统类型(只给安卓用户下发某个广告). ABTest:主要用户建立实验,进行广告策略的分流. 账户:创建推广计划时,还需要指定账户,账户会充值一定的金额.当一条广告下发时,将消耗这个账户的一部分金额. 核心功能短信任务和息任务是系统的核心,以这两个触点触达用户.素材自动化也是一个比较核心的功能,以自动化的方式来生成素材,能提升素材的生成效率. 短信任务:在指定时间,向客群发送短信. 消息任务:在指定时间,向客群发送消息. 素材自动化:主要用于自动化生成素材.运营人员自己创建一张图片的成本比较高,如果可以根据用户上传图片的模板信息来组合成一系列的素材,那么素材创建将会更加的高效. 扩展功能这一部分是由其他部分产生的扩展功能. 任务执行信息:任务执行过程的信息:比如调用短信接口的次数,成功数以及失败数. 任务监控:主要用于监控任务的执行情况,当任务执行满足一定的条件时(比如任务开始5分钟之内没有执行成功的记录),将会进行任务预警. 任务预警:主要通过短信和邮件的方式告知开发人员任务执行异常. 定时清理任务:将超过一定时间点的数据清除(比如半年). 报表订阅:这个主要和报表功能相关,当用户订阅报表时,将通过邮件发送给用户. 效果数据这一部分主要用于追踪短信和消息以及广告的执行情况,但是这类数据有个很明显的特点,它们不是实时的产生效果数据的,比如一条短信下发之后,可能由于短信运营商或者用户原因(比如停机)导致无法接收到短信,那么就需要追踪一个时间段发送出去的短信,那么就有个问题:通过什么方式来追踪呢? 在我们的系统中,创建一个短信任务时,将同时为每个短信内容创建一个模板id(通过对接短信平台),也就是短信的唯一标识.发送短信时,只要通过这个标识调用短信平台接口就可以了.除此之外,短信的发送状态一般由短信平台同步到大数据的Hive库中,运营平台需要每天去拉取某个时间段的短信状态信息(比如截止到短信发送后一周,仍然要拉取短信状态信息). 消息任务的效果追踪和短信是类似的,至于广告,主要对Hive库的广告下发表、广告展示表还有广告点击表的数据进行统计. 短信任务报表:展示短信最终的效果信息,比如到达量,发送成功量,失败量. 消息任务报表:展示消息最终的效果信息,比如到达量,发送成功量,失败量. 广告报表.展示广告下发量、浏览量、点击量等信息. 形成闭环从用户创建任务,到任务执行,再到查看营销结果,整个系统形成了一个闭环,从上面的图中自上而下也能很明显得看出这一点. 技术栈在我参与开发的运营系统中,主要用到的技术如下图: 数据库系统主要分为四个模块: web模块 配置模块 数据模块 任务执行模块 根据模块的职责,各个模块的表情况如下图: 流程图运营系统其实大部分流程并不复杂,这里简单的描述一下短信任务的一个流程,复杂性在于要把系统的各个模块串联起来.主要流程描述如下: 短信任务执行之前,会有短信模板id的生成(在创建任务的时候会生成,还会有定时任务每天重新生成新的模板id) 拉取任务对应的客群,调用短信接口发送短信 在任务执行过程中,会记录任务执行的情况(任务发送了多少条短信,调用短信发送接口成功数和失败数). 每日的短信任务报表的拉取,以此来查看短信最终的触达情况. 短信任务流程图: 再详细一点,短信任务的执行流程图: 总结这篇文章大致介绍了之前参与开发的运营系统的主要功能,不同的运营系统的设计可能多种多样,需要开发人员发挥想象力,创造更有价值的功能.","categories":[{"name":"方案设计","slug":"方案设计","permalink":"http://example.com/categories/%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"方案设计","slug":"方案设计","permalink":"http://example.com/tags/%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1/"}],"author":"君霖"},{"title":"基于注解的动态数据源实现","slug":"基于注解的动态数据源实现","date":"2021-06-10T10:45:00.000Z","updated":"2021-06-16T05:34:11.000Z","comments":true,"path":"2021/06/10/基于注解的动态数据源实现/","link":"","permalink":"http://example.com/2021/06/10/%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%8A%A8%E6%80%81%E6%95%B0%E6%8D%AE%E6%BA%90%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"基于注解的动态数据源实现需求有些项目不只访问一个数据库,可能需要访问多个数据库,那么就会有一个问题,怎么进行数据源的切换. 动态数据源解决这个需求的一个常见解决方案是使用动态数据源.下面将按部就班的来介绍一下如何实现基于注解的动态数据源.完整的代码请参考https://github.com/CodeShowZz/data-source/tree/master/dynamic-data-source. 第一步:配置数据源将项目中需要使用的数据源放到一个配置文件中,比如叫做jdbc.properties,在我的例子中,我有两个数据源,一个是learning库,另外一个是test库. 数据库配置文件: 123456789spring.datasource.test.driver-class-name=com.mysql.jdbc.Driverspring.datasource.test.jdbc-url=jdbc:mysql://localhost:3306/test?useSSL=false&amp;serverTimezone=GMT%2B8&amp;characterEncoding=UTF-8spring.datasource.test.username=rootspring.datasource.test.password=123456spring.datasource.learning.driver-class-name=com.mysql.jdbc.Driverspring.datasource.learning.jdbc-url=jdbc:mysql://localhost:3306/learning?useSSL=false&amp;serverTimezone=GMT%2B8&amp;characterEncoding=UTF-8spring.datasource.learning.username=rootspring.datasource.learning.password=123456 数据源常量类: 123456public class DataSourceConstants &#123; public static final String DB_LEARNING = &quot;learning&quot;; public static final String DB_TEST= &quot;test&quot;;&#125; 动态数据源类: 1234567public class DynamicDataSource extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; return DynamicDataSourceContextHolder.getContextKey(); &#125;&#125; 这里使用了一个DynamicDataSourceContextHolder类,将在下面进行讲解. 数据源配置: 123456789101112131415161718192021222324252627282930@EnableAutoConfiguration(exclude = &#123;DataSourceAutoConfiguration.class&#125;)@Configuration@PropertySource(&quot;classpath:jdbc.properties&quot;)@MapperScan(basePackages = &quot;com.dynamic.datasource.dao&quot;)public class DynamicDataSourceConfig &#123; @Bean(DataSourceConstants.DB_LEARNING) @ConfigurationProperties(prefix = &quot;spring.datasource.learning&quot;) public DataSource learningDataSource() &#123; return DataSourceBuilder.create().build(); &#125; @Bean(DataSourceConstants.DB_TEST) @ConfigurationProperties(prefix = &quot;spring.datasource.test&quot;) public DataSource testDataSource() &#123; return DataSourceBuilder.create().build(); &#125; @Bean @Primary public DataSource dynamicDataSource() &#123; Map&lt;Object, Object&gt; dataSourceMap = new HashMap(2); dataSourceMap.put(DataSourceConstants.DB_LEARNING, learningDataSource()); dataSourceMap.put(DataSourceConstants.DB_TEST, testDataSource()); DynamicDataSource dynamicDataSource = new DynamicDataSource(); dynamicDataSource.setTargetDataSources(dataSourceMap); dynamicDataSource.setDefaultTargetDataSource(testDataSource()); return dynamicDataSource; &#125;&#125; 在这里讲一下具体的原理,首先我们定义了两个数据源,然后在dynamicDataSource方法中定义了一个Map,将两个数据源以(名称,数据源)的形式放入.接着调用setTargetDataSources将Map设置进去,并通过setDefaultTargetDataSource设置了默认数据源.在每次执行sql语句时,将通过DynamicDataSource类实现的determineCurrentLookupKey方法返回的key从Map中找到对应的数据源,如果没有找到,将使用默认数据源. 了解了这个原理,那么改变determineCurrentLookupKey方法返回的key就可以实现数据源的切换,那如何改造这个方法使得可以动态切换数据源呢?通常来说,会将它放在ThreadLocal中. 第二步:引入ThreadLocal定义ThreadLocal对象: 123456789101112131415161718192021222324252627public class DynamicDataSourceContextHolder &#123; /** * 动态数据源名称上下文 */ private static final ThreadLocal&lt;String&gt; DATASOURCE_CONTEXT_KEY_HOLDER = new ThreadLocal&lt;&gt;(); /** * 设置/切换数据源 */ public static void setContextKey(String key)&#123; DATASOURCE_CONTEXT_KEY_HOLDER.set(key); &#125; /** * 获取数据源名称 */ public static String getContextKey()&#123; String key = DATASOURCE_CONTEXT_KEY_HOLDER.get(); return key == null? DataSourceConstants.DB_TEST:key; &#125; /** * 删除当前数据源 */ public static void removeContextKey()&#123; DATASOURCE_CONTEXT_KEY_HOLDER.remove(); &#125;&#125; 很清晰可以看到上面通过ThreadLocal来动态的修改数据源对应的key值,以此来决定某次数据库操作使用的是哪个数据源.至此,一个简单的动态数据源实现就搞定了,接下来可以测试一下. 第三步:测试1234567891011@Testpublic void testDynamicDataSource() &#123; Student student = studentDao.queryById(1); System.out.println(student); DynamicDataSourceContextHolder.setContextKey(DataSourceConstants.DB_LEARNING); System.out.println(userDao.selectById(1)); DynamicDataSourceContextHolder.removeContextKey(); DynamicDataSourceContextHolder.setContextKey(DataSourceConstants.DB_TEST); System.out.println(studentDao.queryById(1)); DynamicDataSourceContextHolder.removeContextKey();&#125; 这样,就可以实现动态数据源了,但是可以很清楚的看到,我们需要在做数据库操作时设置ThreadLocal的值,使用后还要清除值,如果能够尽可能消除这种样板代码就更好了.我们可以引入AOP,并自定义注解来做这件事. 第四步:引入AOP注解: 12345678@Target(&#123;ElementType.METHOD,ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface DS &#123; /** * 数据源名称 */ String value() default DataSourceConstants.DB_TEST;&#125; AOP: 12345678910111213141516171819202122232425262728293031323334@Aspect@Componentpublic class DynamicDataSourceAspect &#123; @Pointcut(&quot;@annotation(com.dynamic.datasource.annotation.DS)&quot;) public void dataSourcePointCut() &#123; &#125; @Around(&quot;dataSourcePointCut()&quot;) public Object around(ProceedingJoinPoint joinPoint) throws Throwable&#123; String dsKey = getDSAnnotation(joinPoint).value(); DynamicDataSourceContextHolder.setContextKey(dsKey); try&#123; return joinPoint.proceed(); &#125;finally &#123; DynamicDataSourceContextHolder.removeContextKey(); &#125; &#125; /** * 根据类或方法获取数据源注解指定的值 */ private DS getDSAnnotation(ProceedingJoinPoint joinPoint) &#123; Class&lt;?&gt; targetClass = joinPoint.getTarget().getClass(); DS classAnnotation = targetClass.getAnnotation(DS.class); if (classAnnotation != null) &#123; return classAnnotation; &#125; MethodSignature methodSignature = (MethodSignature) joinPoint.getSignature(); return methodSignature.getMethod().getAnnotation(DS.class); &#125;&#125; 在Dao层接口的类或方法上添加注解: 12345@Mapperpublic interface StudentDao &#123; @DS(DataSourceConstants.DB_TEST) Student queryById(Integer id);&#125; 12345@Mapper@DS(DataSourceConstants.DB_LEARNING)public interface UserDao &#123; User selectById(Integer id);&#125; 第五步:再次测试1234567@Test public void testDynamicDataSourceUseAnnotation() &#123; Student student = studentDao.queryById(1); System.out.println(student); System.out.println(userDao.selectById(1)); System.out.println(studentDao.queryById(1)); &#125; 这样基于注解的动态数据源就实现完成了.","categories":[{"name":"数据源","slug":"数据源","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E6%BA%90/"}],"tags":[{"name":"数据源","slug":"数据源","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E6%BA%90/"}],"author":"John Doe"},{"title":"ABTest分流算法设计与实现","slug":"ABTest分流算法设计","date":"2021-06-08T14:14:00.000Z","updated":"2024-04-05T03:34:51.851Z","comments":true,"path":"2021/06/08/ABTest分流算法设计/","link":"","permalink":"http://example.com/2021/06/08/ABTest%E5%88%86%E6%B5%81%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"ABTest分流算法设计与实现需求有这么一个需求,我们需要建立一个实验,实验有一个实验名称.实验下面有多个分组,每个分组也有个分组名称.当我们创建一个实验的时候,需要同时建立一个或多个分组,并且每个分组都有一个百分比的属性,代表当我们进入一个实验的时候,选择某个分组的可能性有多大,所有的分组的百分比之和为100%. 目的通过实现实验和分组,我们可以把它应用在分流策略中,比如ABTest.考虑这样一个场景,我们要对比三个推荐算法带来的效益,此时我们会给这三个推荐算法分配一定的比例,然后让每次推荐都按这个比例来执行不同的算法,最终再根据一定的换算来统计算法带来的效益. 实现思路我们可以将分组的百分比看成是几条线段,假如总共有100米长,每条线段有一定的长度,我们根据标识(比如hashCode)来对100取模,最终这个数字一定会落在某一条线段上,也就是某个分组上.在我的实现中,将以1000作为模.在这里,我将使用Java语言实现一个简单的分流算法. 完整代码地址为:https://github.com/CodeShowZz/abtest,所有的接口都进行了初步的测试. 步骤一:定义模型123456789public class Lab &#123; private String key; private String name; private List&lt;Group&gt; groupList;&#125; 12345678910111213141516171819202122public class Group &#123; private String key; private String name; /** * 百分比 **/ private BigDecimal ratio; /** * 分组的开始位置 */ private int start; /** * 分组的结束位置 */ private int end;&#125; 步骤二:实现分流工具类这里要实现一个工具类,能够将百分比转换成区间. 12345678910111213public static void assignRangeByRatio(Lab lab) &#123; List&lt;Group&gt; groupList = lab.getGroupList(); int current = 0; for (Group group : groupList) &#123; BigDecimal ratio = group.getRatio(); int count = ratio.multiply(range).setScale(0, RoundingMode.HALF_UP).intValue(); int start = current; int end = current + count - 1; group.setStart(start); group.setEnd(end); current = end + 1; &#125; &#125; 步骤三:获取标识取Hash,将其分配到某个分组中.在我的实现中,如果两次传入的标识key是一样的,那么计算出来的分组位置也是一样的.所以使用这个Hash算法时,可能要根据具体的应用场景来取一个具体的key,比如对于一个用户来说,取值如果要和上次相同,那么可以使用用户id来作为key,如果取值要随机,那么可以取时间戳或者其它属性作为key. 这里我的Hash算法借鉴(可以说是照抄)了HashMap中的Hash算法. 123public static final int hashCode(String key, String value) &#123; return Math.abs(Objects.hashCode(key) ^ Objects.hashCode(value)); &#125; 接着,使用上面的模型并且结合Hash算法来实现分组.分区函数的返回结果就是某一个分组. 1234567891011public static Group partition(String key, Lab lab) &#123; int hashCode = hashCode(key, lab.getName()); int position = hashCode % range.intValue(); List&lt;Group&gt; groupList = lab.getGroupList(); for (Group group : groupList) &#123; if (group.getStart() &lt;= position &amp;&amp; group.getEnd() &gt;= position) &#123; return group; &#125; &#125; return null;&#125; 步骤四:测试通过上面的三个步骤,一个简单的分流算法实现完成.现在我们来假设这样一个场景:据统计,50%的人喜欢数学,30%的人喜欢语文,20%的人喜欢英语,那么现在我们随便找一个人,来猜测它喜欢哪个科目,那么我们就可以使用上面的程序,测试程序如下. 12345678910111213141516171819202122232425262728293031public static void main(String[] args) &#123; Lab subject = new Lab(); Group math = new Group(); math.setRatio(new BigDecimal(0.5)); math.setKey(&quot;math&quot;); math.setName(&quot;数学&quot;); Group chinese = new Group(); chinese.setRatio(new BigDecimal(0.3)); chinese.setKey(&quot;chinese&quot;); chinese.setName(&quot;语文&quot;); Group english = new Group(); english.setRatio(new BigDecimal(0.2)); english.setKey(&quot;english&quot;); english.setName(&quot;英语&quot;); List&lt;Group&gt; groupList = Arrays.asList(math, chinese, english); subject.setGroupList(groupList); subject.setKey(&quot;subject&quot;); subject.setName(&quot;学科&quot;); SplitFlowUtil.splitFlow(subject); Group res = partition(&quot;the boy maybe like math&quot;, subject); System.out.println(res); res = partition(&quot;i am a programmer&quot;, subject); System.out.println(res); &#125; 继续思考很明显,上面的这个程序其实算是一个通用程序,如果设计的算法更加的快捷,API接口更加易用,它完全可以作为一个公司内部的服务来提供给别人调用.所以现在我们要思考如何将它改进成一个公司内部可以使用的程序. 改进一:建立微服务提供添加、更新、删除、查询、分流五个接口来对实验进行操作,在这里使用Restful接口来提供这项服务. 改进二:将模型数据存储到Mysql上面的测试程序只是在本地构造程序,我们可以将模型数据映射成表,然后存储到数据库中,然后通过UI界面来进行CRUD,这一点很容易就可以做到,不再赘述. 改进三:引入Zookeeper很明显,既然要在公司内部使用,那么要保证每个实验都是隶属于某个项目的,首先要保证实验的唯一性,而这又能看出有很明显的层级结构,所以可以引入Zookeeper来存储这些模型数据,而上面的Mysql则用于冗余模型数据. 开始第一次改进先列一下实现上述改进所要引入的一些技术,其中改进二不在本次实现考虑范围.另外在下文中可能不会提供所有的代码,完整的代码将在最后给出Github仓库地址. 序列化框架:Kryo,用于序列化模型数据并将其存储到Zookeeper上 微服务框架:Spring Boot,用于实现一个微服务并提供Restful接口 分布式协调框架:Zookeeper及其API,用于实现模型数据的保存,并形成目录结构. Zookeeper在工程中实现对zookeeper api的调用,主要考虑的操作有4种 节点增加 节点更新 节点删除 节点数据查询 出于更新的复杂性,调用方可能修改实验名称、分组名称以及分组的属性,所以在真正实现中,将使用节点删除加上节点增加来实现节点更新.在这里将不会讨论Zookeeper API的细节,假设读者已经对此有一定的了解和经验. Spring Boot构建一个Spring Boot服务是非常简单的,和上述的Zookeeper类似,我们将对外提供几个api供外部接口调用. 实验创建 实验更新 实验删除 实验查询 根据实验名称进行分流 API如下所示 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 创建实验 * @param lab * @return */ @RequestMapping(value = &quot;/create&quot;, method = RequestMethod.POST) public boolean create(@RequestBody Lab lab) &#123; return labService.create(lab); &#125; /** * 根据projectKey和labKey删除实验 * @param lab * @return */ @RequestMapping(value = &quot;/delete&quot;, method = RequestMethod.POST) public boolean delete(@RequestBody Lab lab) &#123; return labService.delete(lab); &#125; /** * 根据projectKey和labKey查询实验下的分组 * @param projectKey * @param labKey * @return */ @RequestMapping(value = &quot;/query&quot;, method = RequestMethod.GET) public List&lt;Group&gt; query(@RequestParam String projectKey, @RequestParam String labKey) &#123; return labService.query(projectKey,labKey); &#125; /** * 根据projectKey和labKey还有identify来进行分流 得到某个分组 * @param projectKey * @param labKey * @param identify * @return */ @RequestMapping(value = &quot;/partition&quot;, method = RequestMethod.GET) public Group partition(@RequestParam String projectKey, @RequestParam String labKey,@RequestParam String identify) &#123; return labService.partition(projectKey,labKey,identify); &#125; /** * 更新实验 * @param lab * @return */ @RequestMapping(value = &quot;update&quot;,method = RequestMethod.POST) public boolean update(@RequestBody Lab lab) &#123; return labService.update(lab); &#125; 我在模型数据中又引入了几个参数: 1234567891011121314/** * 分流需要的参数,由调用方传入,调用方决定分流所使用的标识 */ private String identify; /** * 某个项目的标识,在ZK中是第一级目录,以来区分各个项目的实验 */ private String projectKey; /** * 在进行更新时,需要传入变更前的实验分组key,以便于删除原来的实验 */ private String oldKey; 这几个参数的作用已经通过注释来表达,这样可以使得服务更加通用和简单. 测试实现完上述的两个改进之后,我们就可以打开PostMan或者其它Http请求工具来对我们提供的接口进行测试了,这里对如何测试不进行展开. 总结在这篇文章中,介绍了一个简单的分流算法的设计以及实现,当然程序还存在很多不足之处,比如异常处理,参数校验,又或者是无法实现多层的分流,这都是值得改进的地方,希望以后有机会再进行改进(程序员经常说的一句话就是下次一定😄).","categories":[{"name":"方案设计","slug":"方案设计","permalink":"http://example.com/categories/%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"方案设计","slug":"方案设计","permalink":"http://example.com/tags/%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1/"}],"author":"君霖"},{"title":"Java equals和hashCode方法规范","slug":"Java equals和hashCode方法规范","date":"2021-04-05T08:03:00.000Z","updated":"2024-04-05T08:50:16.603Z","comments":true,"path":"2021/04/05/Java equals和hashCode方法规范/","link":"","permalink":"http://example.com/2021/04/05/Java%20equals%E5%92%8ChashCode%E6%96%B9%E6%B3%95%E8%A7%84%E8%8C%83/","excerpt":"","text":"什么时候要重写equals方法只当真正需要为对象提供”逻辑相等性”时才重写equals方法 equals方法需要遵守的通用约定 反射性.非空的x引用调用x.equals(x)返回true 对称性.非空的x引用调用x.equals(y)返回true时,y.equals(x)也应该返回true 传递性.非空的x,y,z引用调用x.equals(y)返回true,调用y.equals(z)返回true,那么x.equals(z)也应该返回true 一致性.非空的x,y引用调用x.equals(y)返回true,那么调用多次也应该返回true 非空的x,调用x.equals(null)应该返回false 如何编写一个正确的equals方法 使用==判断两个对象是否是同一个引用,如果是,返回true,这一步是一种优化 使用 instanceof 判断传入的对象是否是正确的类型,如果不是,返回false 对传入的对象进行转型,由于我们第2步进行了instanceof判断,这次转型是安全的 比较满足”逻辑性相等”所需要的字段,如果这些字段都相等,那么返回true. 对于非float和double类型的基本类型变量,使用==进行比较 对于对象引用,使用对应的equals方法进行比较,一些对象引用可能为空,那么应该使用Objects.equals()方法进行比较 对于float字段,使用静态的 Float.compare(float, float)进行比较. 对于double字段, 使用静态的Double.compare(double, double)进行比较. 对于数组元素,根据元素的类型按照上面的规则进行比较,如果每个元素都需要比较,那么使用Arrays.equals()方法进行比较 性能优化 如果某个字段更可能不同,那么应该提前判断,这样可能可以提前返回false. 如果某个字段判断的代价更低,也应该提前判断,这样可能可以提前返回false. 如果有某个由其他字段计算出来的字段(这个字段仅仅作为性能优化判断使用,这个字段不参与equals逻辑性相等比较),那么先判断这个字段是否相等,这样可能可以提前返回false.比如一个多边形有边和长,如果面积不相等,那么就不需要再判断边和长了 重写equals需要重写hashCode方法根据hashCode约定,重写equals方法必须重写hashCode方法如果 HashCode方法规范 当一个应用的对象的hashCode方法被反复调用时,且对象没有进行任何修改,那么hashCode应该不变 如果x.equals(y)方法返回true,那么x和y的hashCode必须相等 如果x.equals(y)方法返回false,那么x和y的hashCode不一定要相等.但是最好使其不相等,这样可以使得在HashMap等数据结构中提升性能 为什么重写equals要重写hashCode如果equals方法相同,hashcode不同,那么使用类似于HashMap的集合类时,那么可能将原本相同的对象Hash到不同一个桶位置,这样再次检索两个”逻辑相等”的对象就检索不到.即使hash到同一个桶中,由于在HashMap中做了优化,如果两个元素的hash值不同,那么就认为是不相等的对象. 如何写一个正确的HashCode方法目的一个好的哈希函数趋向于让不相等的对象返回不同的hash code,并且尽可能使其在哈希表等集合框架类中保证其数据的分散性. 步骤 为字段计算哈希值 如果字段是基础类型,那么使用对应的包装类的hashCode方法来获取哈希值 如果字段是对象引用,如果字段为null,那么通常认为哈希值为0,如果该字段对应的对象的equals方法中又递归的判断了其它字段,那么就递归调用该对象的hashCode方法. 如果字段是一个数组,对数组的每个元素计算哈希值.如果不需要数组里的元素参与计算,那么最好返回一个不是0的常数.如果所有的元素需要参与计算,那么使用Arrays.hashCode方法 第一个字段的哈希值为result,那么从第二个字段开始的哈希值称为c,那么result=result * 31 + c,依次累加 技巧通常来说,euqals方法哪些字段参与比较,hashCode方法就哪些字段去计算哈希值 性能优化如果一个对象是不可变的,那么可以考虑将hash值缓存起来 结论对equals方法和hashCode方法需要注意基本的规则,但大多数工具类都可以为我们生成这个两个方法,所以实际上对于如何写正确的equals方法和hashCode方法一般很少实践. 参考资料 effective java item 10 Obey the general contract when overriding equalsObey the g eneral contract effective java item 11 Always override hashCode when you override equals","categories":[{"name":"java基础","slug":"java基础","permalink":"http://example.com/categories/java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"http://example.com/tags/java%E5%9F%BA%E7%A1%80/"}],"author":"君霖"}],"categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"JVM","slug":"JVM","permalink":"http://example.com/categories/JVM/"},{"name":"kafka","slug":"kafka","permalink":"http://example.com/categories/kafka/"},{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"redis","slug":"redis","permalink":"http://example.com/categories/redis/"},{"name":"spring","slug":"spring","permalink":"http://example.com/categories/spring/"},{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"方案设计","slug":"方案设计","permalink":"http://example.com/categories/%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1/"},{"name":"数据源","slug":"数据源","permalink":"http://example.com/categories/%E6%95%B0%E6%8D%AE%E6%BA%90/"},{"name":"java基础","slug":"java基础","permalink":"http://example.com/categories/java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"JVM","slug":"JVM","permalink":"http://example.com/tags/JVM/"},{"name":"kafka","slug":"kafka","permalink":"http://example.com/tags/kafka/"},{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"},{"name":"spring","slug":"spring","permalink":"http://example.com/tags/spring/"},{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"方案设计","slug":"方案设计","permalink":"http://example.com/tags/%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1/"},{"name":"数据源","slug":"数据源","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E6%BA%90/"},{"name":"java基础","slug":"java基础","permalink":"http://example.com/tags/java%E5%9F%BA%E7%A1%80/"}]}